{
  "baseline_perplexity": 78.16070556640625,
  "compressed_perplexity": 5367.87939453125,
  "longbench_results": {
    "baseline": {
      "narrativeqa": 405.4547119140625,
      "hotpotqa": 269.3837890625,
      "2wikimqa": 420.951904296875,
      "musique": 211.1696014404297,
      "dureader": 68.05569458007812
    },
    "compressed": {
      "narrativeqa": 1546.690185546875,
      "hotpotqa": 1113.2940673828125,
      "2wikimqa": 1364.1710205078125,
      "musique": 664.7886962890625,
      "dureader": 361.1430358886719
    }
  },
  "config": {
    "name": "distilgpt2",
    "input_dim": 64,
    "latent_dim": 32,
    "batch_size": 64,
    "num_epochs": 10,
    "lr": 0.0001,
    "seed": 42,
    "head_dim": 64,
    "buffer_mult": 2,
    "num_hidden_layers": 6,
    "lm_batch_size": 1,
<<<<<<< HEAD
    "num_key_value_heads": 12,
=======
    "num_attention_heads": 12,
>>>>>>> main
    "eval_interval": 100,
    "config": "src/configs/default_config.json",
    "output_dir": "models",
    "num_train_texts": 10000,
    "num_eval_texts": 200,
    "device": "cuda",
    "max_seq_len": 256,
    "model_name": "distilgpt2",
    "num_runs": 5,
    "cache_sizes": [
      1.0,
      10.0,
      100.0,
      1000.0
    ]
  }
}