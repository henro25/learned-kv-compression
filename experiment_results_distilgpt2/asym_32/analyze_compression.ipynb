{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latent Dim</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Raw PPL</th>\n",
       "      <th>AE PPL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>WikiText</td>\n",
       "      <td>76.19</td>\n",
       "      <td>5049.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>WikiText</td>\n",
       "      <td>76.19</td>\n",
       "      <td>2192.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>WikiText</td>\n",
       "      <td>76.19</td>\n",
       "      <td>167.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Latent Dim   Dataset Raw PPL   AE PPL\n",
       "0           8  WikiText   76.19  5049.08\n",
       "1          16  WikiText   76.19  2192.71\n",
       "2          32  WikiText   76.19   167.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LaTeX Table:\n",
      "\\begin{table}\n",
      "\\caption{Perplexity Comparison vs. Latent Dimension (No Compression)}\n",
      "\\label{tab:perplexity_vs_latent_dim}\n",
      "\\begin{tabular}{rlll}\n",
      "\\toprule\n",
      "Latent Dim & Dataset & Raw PPL & AE PPL \\\\\n",
      "\\midrule\n",
      "8 & WikiText & 76.19 & 5049.08 \\\\\n",
      "16 & WikiText & 76.19 & 2192.71 \\\\\n",
      "32 & WikiText & 76.19 & 167.00 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n",
      "\n",
      "Perplexity vs. Latent Dimension plots (log y-axis) and table (with LaTeX output) saved/printed.\n"
     ]
    }
   ],
   "source": [
    "# KV‑cache compression analysis (open‑source only)\n",
    "# ------------------------------------------------\n",
    "import json, glob, re, statistics, itertools, os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Optional, Dict, Any, List\n",
    "\n",
    "# Ensure the plots directory exists\n",
    "plots_dir = \"./plots\"\n",
    "os.makedirs(plots_dir, exist_ok=True)\n",
    "\n",
    "# 1) locate result files in the current directory\n",
    "files = glob.glob(\"benchmark_results_distilgpt2_*.json\")\n",
    "if not files:\n",
    "    raise FileNotFoundError(\"No benchmark_results_distilgpt2_*.json files in this folder!\")\n",
    "\n",
    "records: List[Dict[str, Any]] = []\n",
    "\n",
    "# Function to extract latent dimension from filename\n",
    "def get_latent_dim(filename: str) -> Optional[int]:\n",
    "    match_ld = re.search(r\"distilgpt2_(\\d+)\\.json$\", filename)\n",
    "    if match_ld:\n",
    "        return int(match_ld.group(1))\n",
    "    return None\n",
    "\n",
    "for path in files:\n",
    "    latent_dim = get_latent_dim(path)\n",
    "    if latent_dim is not None:\n",
    "        with open(path) as fp:\n",
    "            res = json.load(fp)\n",
    "\n",
    "        raw_ppl_wiki = res.get(\"raw_baseline_ppl\")\n",
    "        ae_ppl_wiki_none = res[\"perplexities\"].get(\"none\", {}).get(\"ae_compressed_ppl\")\n",
    "\n",
    "        if raw_ppl_wiki is not None and ae_ppl_wiki_none is not None:\n",
    "            records.append(dict(\n",
    "                latent_dim=latent_dim,\n",
    "                raw_ppl=raw_ppl_wiki,\n",
    "                ae_ppl=ae_ppl_wiki_none,\n",
    "                dataset=\"WikiText\"\n",
    "            ))\n",
    "\n",
    "        lb_baseline = res.get(\"longbench\", {}).get(\"baseline\", {})\n",
    "        lb_compressed_none = res.get(\"longbench\", {}).get(\"compressed\", {}).get(\"none\", {})\n",
    "\n",
    "        for task, base_ppl in lb_baseline.items():\n",
    "            comp_ppl = lb_compressed_none.get(task)\n",
    "            if comp_ppl is not None:\n",
    "                records.append(dict(\n",
    "                    latent_dim=latent_dim,\n",
    "                    raw_ppl=base_ppl,\n",
    "                    ae_ppl=comp_ppl,\n",
    "                    dataset=f\"LongBench ({task})\"\n",
    "                ))\n",
    "\n",
    "df = pd.DataFrame(records).sort_values([\"latent_dim\", \"dataset\"]).reset_index(drop=True)\n",
    "\n",
    "latent_dims = sorted(df['latent_dim'].dropna().unique())\n",
    "longbench_tasks = sorted([d.split('(')[1][:-1] for d in df['dataset'].unique() if d.startswith(\"LongBench\")])\n",
    "\n",
    "# Plot for WikiText Perplexity (Log Scale)\n",
    "plt.figure(figsize=(8, 5))\n",
    "wiki_data = df[df['dataset'] == 'WikiText'].dropna(subset=['latent_dim', 'raw_ppl', 'ae_ppl']).sort_values('latent_dim')\n",
    "if not wiki_data.empty:\n",
    "    raw_ppl_baseline_wiki = wiki_data['raw_ppl'].iloc[0]\n",
    "    plt.plot(wiki_data['latent_dim'], [raw_ppl_baseline_wiki] * len(wiki_data), linestyle='--', marker='o', label='Raw Baseline')\n",
    "    plt.plot(wiki_data['latent_dim'], wiki_data['ae_ppl'], marker='x', label='AE')\n",
    "    plt.xlabel(\"Latent Dimension\")\n",
    "    plt.ylabel(\"Perplexity (Log Scale)\")\n",
    "    plt.title(\"WikiText Perplexity vs. Latent Dimension\")\n",
    "    plt.yscale('log')\n",
    "    plt.legend()\n",
    "    plt.grid(True, which=\"both\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(plots_dir, \"exp1_wikitext_perplexity_vs_latent_dim_logy.png\"))\n",
    "    plt.close()\n",
    "\n",
    "# Plot for LongBench Perplexity (averaged across tasks, Log Scale)\n",
    "if longbench_tasks:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    longbench_data = df[df['dataset'].str.startswith('LongBench')].dropna(subset=['latent_dim', 'raw_ppl', 'ae_ppl'])\n",
    "    if not longbench_data.empty:\n",
    "        avg_raw_ppl_lb = longbench_data.groupby('latent_dim')['raw_ppl'].mean()\n",
    "        avg_ae_ppl_lb = longbench_data.groupby('latent_dim')['ae_ppl'].mean()\n",
    "\n",
    "        plt.plot(avg_raw_ppl_lb.index, avg_raw_ppl_lb.values, linestyle='--', marker='o', label='Avg. Raw Baseline')\n",
    "        plt.plot(avg_ae_ppl_lb.index, avg_ae_ppl_lb.values, marker='x', label='Avg. AE')\n",
    "        plt.xlabel(\"Latent Dimension\")\n",
    "        plt.ylabel(\"Average Perplexity (LongBench, Log Scale)\")\n",
    "        plt.yscale('log')\n",
    "        plt.title(\"Average LongBench Perplexity vs. Latent Dimension\")\n",
    "        plt.legend()\n",
    "        plt.grid(True, which=\"both\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(plots_dir, \"exp1_longbench_avg_perplexity_vs_latent_dim_logy.png\"))\n",
    "        plt.close()\n",
    "\n",
    "# Create Table Data\n",
    "table_data = []\n",
    "wiki_data_table = df[df['dataset'] == 'WikiText'].dropna(subset=['latent_dim', 'raw_ppl', 'ae_ppl']).sort_values('latent_dim')\n",
    "if not wiki_data_table.empty:\n",
    "    raw_ppl_baseline_wiki_table = wiki_data_table['raw_ppl'].iloc[0]\n",
    "    for index, row in wiki_data_table.iterrows():\n",
    "        table_data.append({\n",
    "            \"Latent Dim\": int(row['latent_dim']),\n",
    "            \"Dataset\": \"WikiText\",\n",
    "            \"Raw PPL\": f\"{raw_ppl_baseline_wiki_table:.2f}\",\n",
    "            \"AE PPL\": f\"{row['ae_ppl']:.2f}\"\n",
    "        })\n",
    "\n",
    "longbench_data_table = df[df['dataset'].str.startswith('LongBench')].dropna(subset=['latent_dim', 'raw_ppl', 'ae_ppl'])\n",
    "if not longbench_data_table.empty:\n",
    "    avg_results_lb = longbench_data_table.groupby('latent_dim').agg(\n",
    "        Avg_Raw_PPL=('raw_ppl', 'mean'),\n",
    "        Avg_AE_PPL=('ae_ppl', 'mean')\n",
    "    ).reset_index()\n",
    "    for index, row in avg_results_lb.iterrows():\n",
    "        table_data.append({\n",
    "            \"Latent Dim\": int(row['latent_dim']),\n",
    "            \"Dataset\": \"LongBench (Avg)\",\n",
    "            \"Raw PPL\": f\"{row['Avg_Raw_PPL']:.2f}\",\n",
    "            \"AE PPL\": f\"{row['Avg_AE_PPL']:.2f}\"\n",
    "        })\n",
    "\n",
    "table_df = pd.DataFrame(table_data)\n",
    "display(table_df)\n",
    "\n",
    "# Create LaTeX Table\n",
    "latex_table = table_df.to_latex(index=False, float_format=\"%.2f\", caption=\"Perplexity Comparison vs. Latent Dimension (No Compression)\", label=\"tab:perplexity_vs_latent_dim\")\n",
    "print(\"\\nLaTeX Table:\")\n",
    "print(latex_table)\n",
    "\n",
    "print(f\"\\nPerplexity vs. Latent Dimension plots (log y-axis) and table (with LaTeX output) saved/printed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latent Dim</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>AE PPL</th>\n",
       "      <th>Raw (32-bit) PPL</th>\n",
       "      <th>Raw (2-bit) PPL</th>\n",
       "      <th>Raw (4-bit) PPL</th>\n",
       "      <th>Raw (8-bit) PPL</th>\n",
       "      <th>Raw (16-bit) PPL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>WikiText</td>\n",
       "      <td>5049.08</td>\n",
       "      <td>76.19</td>\n",
       "      <td>1310.36</td>\n",
       "      <td>104.02</td>\n",
       "      <td>76.30</td>\n",
       "      <td>76.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>WikiText</td>\n",
       "      <td>2192.71</td>\n",
       "      <td>72.66</td>\n",
       "      <td>1150.16</td>\n",
       "      <td>97.59</td>\n",
       "      <td>72.62</td>\n",
       "      <td>72.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>WikiText</td>\n",
       "      <td>167.00</td>\n",
       "      <td>72.66</td>\n",
       "      <td>1150.16</td>\n",
       "      <td>97.59</td>\n",
       "      <td>72.62</td>\n",
       "      <td>72.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Latent Dim   Dataset   AE PPL Raw (32-bit) PPL Raw (2-bit) PPL  \\\n",
       "0           8  WikiText  5049.08            76.19         1310.36   \n",
       "1          16  WikiText  2192.71            72.66         1150.16   \n",
       "2          32  WikiText   167.00            72.66         1150.16   \n",
       "\n",
       "  Raw (4-bit) PPL Raw (8-bit) PPL Raw (16-bit) PPL  \n",
       "0          104.02           76.30            76.19  \n",
       "1           97.59           72.62            72.65  \n",
       "2           97.59           72.62            72.65  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LaTeX Table:\n",
      "\\begin{table}\n",
      "\\caption{Perplexity Comparison: AE vs. Raw Quantization Levels}\n",
      "\\label{tab:perplexity_comparison_all_quant}\n",
      "\\begin{tabular}{rlllllll}\n",
      "\\toprule\n",
      "Latent Dim & Dataset & AE PPL & Raw (32-bit) PPL & Raw (2-bit) PPL & Raw (4-bit) PPL & Raw (8-bit) PPL & Raw (16-bit) PPL \\\\\n",
      "\\midrule\n",
      "8 & WikiText & 5049.08 & 76.19 & 1310.36 & 104.02 & 76.30 & 76.19 \\\\\n",
      "16 & WikiText & 2192.71 & 72.66 & 1150.16 & 97.59 & 72.62 & 72.65 \\\\\n",
      "32 & WikiText & 167.00 & 72.66 & 1150.16 & 97.59 & 72.62 & 72.65 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n",
      "\n",
      "Perplexity comparison plots (log y-axis) and table (with LaTeX output) saved/printed.\n"
     ]
    }
   ],
   "source": [
    "# KV‑cache compression analysis (open‑source only)\n",
    "# ------------------------------------------------\n",
    "import json, glob, re, statistics, itertools, os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Optional, Dict, Any, List\n",
    "\n",
    "# Ensure the plots directory exists\n",
    "plots_dir = \"./plots\"\n",
    "os.makedirs(plots_dir, exist_ok=True)\n",
    "\n",
    "# 1) locate result files in the current directory\n",
    "files = glob.glob(\"benchmark_results_distilgpt2_*.json\")\n",
    "if not files:\n",
    "    raise FileNotFoundError(\"No benchmark_results_distilgpt2_*.json files in this folder!\")\n",
    "\n",
    "records: List[Dict[str, Any]] = []\n",
    "\n",
    "# Function to extract latent dimension from filename\n",
    "def get_latent_dim(filename: str) -> Optional[int]:\n",
    "    match_ld = re.search(r\"distilgpt2_(\\d+)\\.json$\", filename)\n",
    "    if match_ld:\n",
    "        return int(match_ld.group(1))\n",
    "    return None\n",
    "\n",
    "quantization_levels = [2, 4, 8, 16, 32]\n",
    "\n",
    "for path in files:\n",
    "    latent_dim = get_latent_dim(path)\n",
    "    if latent_dim is not None:\n",
    "        with open(path) as fp:\n",
    "            res = json.load(fp)\n",
    "\n",
    "        raw_ppl: float = res[\"raw_baseline_ppl\"]\n",
    "        ae_ppl_none: Optional[float] = res[\"perplexities\"].get(\"none\", {}).get(\"ae_compressed_ppl\")\n",
    "        kv_ppl_quant = {bits: res[\"perplexities\"].get(str(bits), {}).get(\"kv_cache_baseline_ppl\") for bits in quantization_levels}\n",
    "\n",
    "        if raw_ppl is not None and ae_ppl_none is not None:\n",
    "            record = {\"latent_dim\": latent_dim, \"raw_ppl\": raw_ppl, \"ae_ppl\": ae_ppl_none, \"dataset\": \"WikiText\"}\n",
    "            record.update({f\"raw_quant{b}_ppl\": kv_ppl_quant[b] for b in quantization_levels})\n",
    "            records.append(record)\n",
    "\n",
    "        lb_baseline = res.get(\"longbench\", {}).get(\"baseline\", {})\n",
    "        lb_compressed_none = res.get(\"longbench\", {}).get(\"compressed\", {}).get(\"none\", {})\n",
    "        lb_compressed_quant = {\n",
    "            bits: res.get(\"longbench\", {}).get(\"compressed\", {}).get(str(bits), {}) for bits in quantization_levels\n",
    "        }\n",
    "\n",
    "        for task, base_ppl in lb_baseline.items():\n",
    "            comp_ppl_none = lb_compressed_none.get(task)\n",
    "            comp_ppl_quant = {bits: lb_compressed_quant[bits].get(task) for bits in quantization_levels}\n",
    "            if comp_ppl_none is not None:\n",
    "                record = {\"latent_dim\": latent_dim, \"raw_ppl\": base_ppl, \"ae_ppl\": comp_ppl_none, \"dataset\": f\"LongBench ({task})\"}\n",
    "                record.update({f\"raw_quant{b}_ppl\": comp_ppl_quant[b] for b in quantization_levels})\n",
    "                records.append(record)\n",
    "\n",
    "df = pd.DataFrame(records).sort_values([\"latent_dim\", \"dataset\"]).reset_index(drop=True)\n",
    "\n",
    "latent_dims = sorted(df['latent_dim'].dropna().unique())\n",
    "longbench_tasks = sorted([d.split('(')[1][:-1] for d in df['dataset'].unique() if d.startswith(\"LongBench\")])\n",
    "\n",
    "# Plot for WikiText Perplexity Comparison (Log Scale)\n",
    "plt.figure(figsize=(10, 6))\n",
    "wiki_data = df[df['dataset'] == 'WikiText'].dropna(subset=['latent_dim', 'raw_ppl', 'ae_ppl'] + [f'raw_quant{b}_ppl' for b in quantization_levels]).sort_values('latent_dim')\n",
    "if not wiki_data.empty:\n",
    "    plt.plot(wiki_data['latent_dim'], wiki_data['raw_ppl'], linestyle='--', marker='o', label='Raw Baseline (32-bit)')\n",
    "    for bits in quantization_levels:\n",
    "        plt.plot(wiki_data['latent_dim'], wiki_data[f'raw_quant{bits}_ppl'], marker='v', label=f'Raw ({bits}-bit)')\n",
    "    plt.plot(wiki_data['latent_dim'], wiki_data['ae_ppl'], marker='x', label='AE (No Comp)')\n",
    "    plt.xlabel(\"Latent Dimension\")\n",
    "    plt.ylabel(\"Perplexity (Log Scale)\")\n",
    "    plt.title(\"WikiText Perplexity vs. Latent Dimension\")\n",
    "    plt.yscale('log')\n",
    "    plt.legend()\n",
    "    plt.grid(True, which=\"both\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(plots_dir, \"exp1_wikitext_perplexity_vs_latent_dim_all_quant_logy.png\"))\n",
    "    plt.close()\n",
    "\n",
    "# Plot for LongBench Perplexity Comparison (averaged across tasks, Log Scale)\n",
    "if longbench_tasks:\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    longbench_data = df[df['dataset'].str.startswith('LongBench')].dropna(subset=['latent_dim', 'raw_ppl', 'ae_ppl'] + [f'raw_quant{b}_ppl' for b in quantization_levels])\n",
    "    if not longbench_data.empty:\n",
    "        avg_raw_ppl_lb = longbench_data.groupby('latent_dim')['raw_ppl'].mean()\n",
    "        avg_ae_ppl_lb = longbench_data.groupby('latent_dim')['ae_ppl'].mean()\n",
    "        avg_raw_quant_ppl_lb = {\n",
    "            bits: longbench_data.groupby('latent_dim')[f'raw_quant{bits}_ppl'].mean() for bits in quantization_levels\n",
    "        }\n",
    "\n",
    "        plt.plot(avg_raw_ppl_lb.index, avg_raw_ppl_lb.values, linestyle='--', marker='o', label='Avg. Raw Baseline (32-bit)')\n",
    "        for bits in quantization_levels:\n",
    "            plt.plot(avg_raw_quant_ppl_lb[bits].index, avg_raw_quant_ppl_lb[bits].values, marker='v', label=f'Avg. Raw ({bits}-bit)')\n",
    "        plt.plot(avg_ae_ppl_lb.index, avg_ae_ppl_lb.values, marker='x', label='Avg. AE (No Comp)')\n",
    "        plt.xlabel(\"Latent Dimension\")\n",
    "        plt.ylabel(\"Average Perplexity (LongBench, Log Scale)\")\n",
    "        plt.yscale('log')\n",
    "        plt.title(\"Average LongBench Perplexity vs. Latent Dimension\")\n",
    "        plt.legend()\n",
    "        plt.grid(True, which=\"both\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(plots_dir, \"exp1_longbench_avg_perplexity_vs_latent_dim_all_quant_logy.png\"))\n",
    "        plt.close()\n",
    "\n",
    "# Create Table Data\n",
    "table_data = []\n",
    "wiki_data_table = df[df['dataset'] == 'WikiText'].dropna(subset=['latent_dim', 'raw_ppl', 'ae_ppl'] + [f'raw_quant{b}_ppl' for b in quantization_levels]).sort_values('latent_dim')\n",
    "if not wiki_data_table.empty:\n",
    "    for index, row in wiki_data_table.iterrows():\n",
    "        table_row = {\"Latent Dim\": int(row['latent_dim']), \"Dataset\": \"WikiText\", \"AE PPL\": f\"{row['ae_ppl']:.2f}\", \"Raw (32-bit) PPL\": f\"{row['raw_ppl']:.2f}\"}\n",
    "        table_row.update({f\"Raw ({b}-bit) PPL\": f\"{row[f'raw_quant{b}_ppl']:.2f}\" for b in quantization_levels})\n",
    "        table_data.append(table_row)\n",
    "\n",
    "longbench_data_table = df[df['dataset'].str.startswith('LongBench')].dropna(subset=['latent_dim', 'raw_ppl', 'ae_ppl'] + [f'raw_quant{b}_ppl' for b in quantization_levels])\n",
    "if not longbench_data_table.empty:\n",
    "    agg_funcs = {'Avg_AE_PPL': ('ae_ppl', 'mean'), 'Avg_Raw_PPL': ('raw_ppl', 'mean')}\n",
    "    agg_funcs.update({f'Avg_Raw_{b}bit_PPL': (f'raw_quant{b}_ppl', 'mean') for b in quantization_levels})\n",
    "    avg_results_lb = longbench_data_table.groupby('latent_dim').agg(**agg_funcs).reset_index()\n",
    "    for index, row in avg_results_lb.iterrows():\n",
    "        table_row = {\"Latent Dim\": int(row['latent_dim']), \"Dataset\": \"LongBench (Avg)\", \"Avg. AE PPL\": f\"{row['Avg_AE_PPL']:.2f}\", \"Avg. Raw (32-bit) PPL\": f\"{row['Avg_Raw_PPL']:.2f}\"}\n",
    "        table_row.update({f\"Avg. Raw ({b}-bit) PPL\": f\"{row[f'Avg_Raw_{b}bit_PPL']:.2f}\" for b in quantization_levels})\n",
    "        table_data.append(table_row)\n",
    "\n",
    "table_df = pd.DataFrame(table_data)\n",
    "display(table_df)\n",
    "\n",
    "# Create LaTeX Table\n",
    "latex_table = table_df.to_latex(index=False, float_format=\"%.2f\", caption=\"Perplexity Comparison: AE vs. Raw Quantization Levels\", label=\"tab:perplexity_comparison_all_quant\")\n",
    "print(\"\\nLaTeX Table:\")\n",
    "print(latex_table)\n",
    "\n",
    "print(f\"\\nPerplexity comparison plots (log y-axis) and table (with LaTeX output) saved/printed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latent Dim</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>AE PPL</th>\n",
       "      <th>Raw (2-bit) PPL</th>\n",
       "      <th>Raw (4-bit) PPL</th>\n",
       "      <th>Raw (8-bit) PPL</th>\n",
       "      <th>Raw (16-bit) PPL</th>\n",
       "      <th>Raw (32-bit) PPL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>WikiText</td>\n",
       "      <td>5049.08</td>\n",
       "      <td>1310.36</td>\n",
       "      <td>104.02</td>\n",
       "      <td>76.30</td>\n",
       "      <td>76.19</td>\n",
       "      <td>76.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>WikiText</td>\n",
       "      <td>2192.71</td>\n",
       "      <td>1150.16</td>\n",
       "      <td>97.59</td>\n",
       "      <td>72.62</td>\n",
       "      <td>72.65</td>\n",
       "      <td>72.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>WikiText</td>\n",
       "      <td>167.00</td>\n",
       "      <td>1150.16</td>\n",
       "      <td>97.59</td>\n",
       "      <td>72.62</td>\n",
       "      <td>72.65</td>\n",
       "      <td>72.66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Latent Dim   Dataset   AE PPL Raw (2-bit) PPL Raw (4-bit) PPL  \\\n",
       "0           8  WikiText  5049.08         1310.36          104.02   \n",
       "1          16  WikiText  2192.71         1150.16           97.59   \n",
       "2          32  WikiText   167.00         1150.16           97.59   \n",
       "\n",
       "  Raw (8-bit) PPL Raw (16-bit) PPL Raw (32-bit) PPL  \n",
       "0           76.30            76.19            76.19  \n",
       "1           72.62            72.65            72.66  \n",
       "2           72.62            72.65            72.66  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LaTeX Table:\n",
      "\\begin{table}\n",
      "\\caption{Perplexity Comparison: AE vs. Raw Quantization Levels}\n",
      "\\label{tab:perplexity_comparison_all_quant}\n",
      "\\begin{tabular}{rlllllll}\n",
      "\\toprule\n",
      "Latent Dim & Dataset & AE PPL & Raw (2-bit) PPL & Raw (4-bit) PPL & Raw (8-bit) PPL & Raw (16-bit) PPL & Raw (32-bit) PPL \\\\\n",
      "\\midrule\n",
      "8 & WikiText & 5049.08 & 1310.36 & 104.02 & 76.30 & 76.19 & 76.19 \\\\\n",
      "16 & WikiText & 2192.71 & 1150.16 & 97.59 & 72.62 & 72.65 & 72.66 \\\\\n",
      "32 & WikiText & 167.00 & 1150.16 & 97.59 & 72.62 & 72.65 & 72.66 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n",
      "\n",
      "Perplexity comparison plots (log y-axis) and table (with LaTeX output) saved/printed.\n"
     ]
    }
   ],
   "source": [
    "# KV‑cache compression analysis (open‑source only)\n",
    "# ------------------------------------------------\n",
    "import json, glob, re, statistics, itertools, os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Optional, Dict, Any, List\n",
    "\n",
    "# Ensure the plots directory exists\n",
    "plots_dir = \"./plots\"\n",
    "os.makedirs(plots_dir, exist_ok=True)\n",
    "\n",
    "# 1) locate result files in the current directory\n",
    "files = glob.glob(\"benchmark_results_distilgpt2_*.json\")\n",
    "if not files:\n",
    "    raise FileNotFoundError(\"No benchmark_results_distilgpt2_*.json files in this folder!\")\n",
    "\n",
    "records: List[Dict[str, Any]] = []\n",
    "\n",
    "# Function to extract latent dimension from filename\n",
    "def get_latent_dim(filename: str) -> Optional[int]:\n",
    "    match_ld = re.search(r\"distilgpt2_(\\d+)\\.json$\", filename)\n",
    "    if match_ld:\n",
    "        return int(match_ld.group(1))\n",
    "    return None\n",
    "\n",
    "quantization_levels = [2, 4, 8, 16, 32]\n",
    "\n",
    "for path in files:\n",
    "    latent_dim = get_latent_dim(path)\n",
    "    if latent_dim is not None:\n",
    "        with open(path) as fp:\n",
    "            res = json.load(fp)\n",
    "\n",
    "        raw_ppl: float = res[\"raw_baseline_ppl\"]\n",
    "        ae_ppl_none: Optional[float] = res[\"perplexities\"].get(\"none\", {}).get(\"ae_compressed_ppl\")\n",
    "        kv_ppl_quant = {bits: res[\"perplexities\"].get(str(bits), {}).get(\"kv_cache_baseline_ppl\") for bits in quantization_levels}\n",
    "\n",
    "        if raw_ppl is not None and ae_ppl_none is not None:\n",
    "            record = {\"latent_dim\": latent_dim, \"raw_ppl\": raw_ppl, \"ae_ppl\": ae_ppl_none, \"dataset\": \"WikiText\"}\n",
    "            record.update({f\"raw_quant{b}_ppl\": kv_ppl_quant[b] for b in quantization_levels})\n",
    "            records.append(record)\n",
    "\n",
    "        lb_baseline = res.get(\"longbench\", {}).get(\"baseline\", {})\n",
    "        lb_compressed_none = res.get(\"longbench\", {}).get(\"compressed\", {}).get(\"none\", {})\n",
    "        lb_compressed_quant = {\n",
    "            bits: res.get(\"longbench\", {}).get(\"compressed\", {}).get(str(bits), {}) for bits in quantization_levels\n",
    "        }\n",
    "\n",
    "        for task, base_ppl in lb_baseline.items():\n",
    "            comp_ppl_none = lb_compressed_none.get(task)\n",
    "            comp_ppl_quant = {bits: lb_compressed_quant[bits].get(task) for bits in quantization_levels}\n",
    "            if comp_ppl_none is not None:\n",
    "                record = {\"latent_dim\": latent_dim, \"raw_ppl\": base_ppl, \"ae_ppl\": comp_ppl_none, \"dataset\": f\"LongBench ({task})\"}\n",
    "                record.update({f\"raw_quant{b}_ppl\": comp_ppl_quant[b] for b in quantization_levels})\n",
    "                records.append(record)\n",
    "\n",
    "df = pd.DataFrame(records).sort_values([\"latent_dim\", \"dataset\"]).reset_index(drop=True)\n",
    "\n",
    "latent_dims = sorted(df['latent_dim'].dropna().unique())\n",
    "longbench_tasks = sorted([d.split('(')[1][:-1] for d in df['dataset'].unique() if d.startswith(\"LongBench\")])\n",
    "\n",
    "# Plot for WikiText Perplexity Comparison (Log Scale) - Separate Plots\n",
    "wiki_data = df[df['dataset'] == 'WikiText'].dropna(subset=['latent_dim', 'raw_ppl', 'ae_ppl'] + [f'raw_quant{b}_ppl' for b in quantization_levels]).sort_values('latent_dim')\n",
    "if not wiki_data.empty:\n",
    "    for bits in quantization_levels:\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        plt.plot(wiki_data['latent_dim'], wiki_data[f'raw_quant{bits}_ppl'], marker='v', label=f'Raw ({bits}-bit)')\n",
    "        plt.plot(wiki_data['latent_dim'], wiki_data['ae_ppl'], marker='x', label='AE')\n",
    "        plt.xlabel(\"Latent Dimension\")\n",
    "        plt.ylabel(\"Perplexity (Log Scale)\")\n",
    "        plt.title(f\"WikiText Perplexity vs. Latent Dim - vs. Raw ({bits}-bit)\")\n",
    "        plt.yscale('log')\n",
    "        plt.legend()\n",
    "        plt.grid(True, which=\"both\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(plots_dir, f\"exp1_wikitext_perplexity_vs_latent_dim_quant{bits}_logy.png\"))\n",
    "        plt.close()\n",
    "\n",
    "# Plot for LongBench Perplexity Comparison (averaged across tasks, Log Scale) - Separate Plots\n",
    "if longbench_tasks:\n",
    "    longbench_data = df[df['dataset'].str.startswith('LongBench')].dropna(subset=['latent_dim', 'raw_ppl', 'ae_ppl'] + [f'raw_quant{b}_ppl' for b in quantization_levels])\n",
    "    if not longbench_data.empty:\n",
    "        avg_ae_ppl_lb = longbench_data.groupby('latent_dim')['ae_ppl'].mean()\n",
    "        avg_raw_quant_ppl_lb = {\n",
    "            bits: longbench_data.groupby('latent_dim')[f'raw_quant{bits}_ppl'].mean() for bits in quantization_levels\n",
    "        }\n",
    "\n",
    "        for bits in quantization_levels:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.plot(avg_raw_quant_ppl_lb[bits].index, avg_raw_quant_ppl_lb[bits].values, marker='v', label=f'Avg. Raw ({bits}-bit)')\n",
    "            plt.plot(avg_ae_ppl_lb.index, avg_ae_ppl_lb.values, marker='x', label='Avg. AE')\n",
    "            plt.xlabel(\"Latent Dimension\")\n",
    "            plt.ylabel(\"Average Perplexity (LongBench, Log Scale)\")\n",
    "            plt.title(f\"Avg. LongBench PPL vs. Latent Dim - vs. Raw ({bits}-bit)\")\n",
    "            plt.yscale('log')\n",
    "            plt.legend()\n",
    "            plt.grid(True, which=\"both\")\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(plots_dir, f\"exp1_longbench_avg_perplexity_vs_latent_dim_quant{bits}_logy.png\"))\n",
    "            plt.close()\n",
    "\n",
    "# Create Table Data (as before)\n",
    "table_data = []\n",
    "wiki_data_table = df[df['dataset'] == 'WikiText'].dropna(subset=['latent_dim', 'raw_ppl', 'ae_ppl'] + [f'raw_quant{b}_ppl' for b in quantization_levels]).sort_values('latent_dim')\n",
    "if not wiki_data_table.empty:\n",
    "    for index, row in wiki_data_table.iterrows():\n",
    "        table_row = {\"Latent Dim\": int(row['latent_dim']), \"Dataset\": \"WikiText\", \"AE PPL\": f\"{row['ae_ppl']:.2f}\"}\n",
    "        table_row.update({f\"Raw ({b}-bit) PPL\": f\"{row[f'raw_quant{b}_ppl']:.2f}\" for b in quantization_levels})\n",
    "        table_data.append(table_row)\n",
    "\n",
    "longbench_data_table = df[df['dataset'].str.startswith('LongBench')].dropna(subset=['latent_dim', 'raw_ppl', 'ae_ppl'] + [f'raw_quant{b}_ppl' for b in quantization_levels])\n",
    "if not longbench_data_table.empty:\n",
    "    agg_funcs = {'Avg_AE_PPL': ('ae_ppl', 'mean')}\n",
    "    agg_funcs.update({f'Avg_Raw_{b}bit_PPL': (f'raw_quant{b}_ppl', 'mean') for b in quantization_levels})\n",
    "    avg_results_lb = longbench_data_table.groupby('latent_dim').agg(**agg_funcs).reset_index()\n",
    "    for index, row in avg_results_lb.iterrows():\n",
    "        table_row = {\"Latent Dim\": int(row['latent_dim']), \"Dataset\": \"LongBench (Avg)\", \"Avg. AE PPL\": f\"{row['Avg_AE_PPL']:.2f}\"}\n",
    "        table_row.update({f\"Avg. Raw ({b}-bit) PPL\": f\"{row[f'Avg_Raw_{b}bit_PPL']:.2f}\" for b in quantization_levels})\n",
    "        table_data.append(table_row)\n",
    "\n",
    "table_df = pd.DataFrame(table_data)\n",
    "display(table_df)\n",
    "\n",
    "# Create LaTeX Table (as before)\n",
    "latex_table = table_df.to_latex(index=False, float_format=\"%.2f\", caption=\"Perplexity Comparison: AE vs. Raw Quantization Levels\", label=\"tab:perplexity_comparison_all_quant\")\n",
    "print(\"\\nLaTeX Table:\")\n",
    "print(latex_table)\n",
    "\n",
    "print(f\"\\nPerplexity comparison plots (log y-axis) and table (with LaTeX output) saved/printed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
