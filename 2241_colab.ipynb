{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ta6KkToOAF1M"
      },
      "source": [
        "# Notebook to run learned kv compression scripts on colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prGnb-vKAnzs"
      },
      "source": [
        "Download Repo and Install Requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YbnT8hMBAE49",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "# Download Repo\n",
        "%cd /content\n",
        "!rm -rf learned-kv-compression\n",
        "!git clone -b colab https://henro25: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@github.com/henro25/learned-kv-compression\n",
        "%cd /content/learned-kv-compression/\n",
        "%ls\n",
        "\n",
        "# Install Requirements\n",
        "%pip install -r colab_requirements.txt\n",
        "%pip uninstall gcsfs -y\n",
        "%pip install --upgrade fsspec==2025.3.2\n",
        "%pip install gcsfs==2024.12.0\n",
        "%pip install --upgrade datasets\n",
        "\n",
        "!apt-get update -y\n",
        "!apt-get install -y jq\n",
        "\n",
        "# Enable permissions if needed\n",
        "!chmod +x run_experiments.sh"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./run_experiments.sh configs/distilgpt2_test.json"
      ],
      "metadata": {
        "id": "U7pL1VbTNWy0",
        "outputId": "33f3d0fe-562f-49ca-b8b9-c0d4e928c6ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==== KV Cache Compression Experiment ====\n",
            "Config file: configs/distilgpt2_test.json\n",
            "Working directory: /content/learned-kv-compression\n",
            "========================================\n",
            "Experiment results directory: /content/learned-kv-compression/test_results_distilgpt2\n",
            "Starting experiment at Thu Apr 24 12:35:53 AM UTC 2025\n",
            "Gradient accumulation steps: 2\n",
            "Buffer size: 256\n",
            "Buffer multiplier: 2\n",
            "Max sequence length: 1024\n",
            "Running experiments with the following configuration:\n",
            "Models: ['distilgpt2']\n",
            "Latent dimensions: [8]\n",
            "Learning rates: [0.0005]\n",
            "Cache sizes: [1, 10, 100, 1000]\n",
            "Quantization bits: [4, 8]\n",
            "Epochs: [2]\n",
            "Training texts: [100]\n",
            "Batch sizes: [64]\n",
            "Number of runs: [5]\n",
            "Output directory: /content/learned-kv-compression/test_results_distilgpt2\n",
            "MODEL DIR:  /content/learned-kv-compression/test_results_distilgpt2/distilgpt2/distilgpt2_latent8_lr0.0005\n",
            "\n",
            "================================================================================\n",
            "Training autoencoder with model=distilgpt2, latent_dim=8, lr=0.0005, epochs=2, train_texts=100\n",
            "================================================================================\n",
            "python -m src.dictionary_learning.train --config /content/learned-kv-compression/test_results_distilgpt2/distilgpt2/distilgpt2_latent8_lr0.0005/train_config.json\n",
            "2025-04-24 00:35:57.373126: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-04-24 00:35:57.390778: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1745454957.411924    1798 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1745454957.418472    1798 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-04-24 00:35:57.439999: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "{'batch_size': 64,\n",
            " 'buffer_mult': 2,\n",
            " 'buffer_size': 256,\n",
            " 'cache_sizes': [1, 10, 100, 1000],\n",
            " 'device': 'cuda',\n",
            " 'dtype': 'bf16',\n",
            " 'eval_interval': 1000,\n",
            " 'gradient_accumulation_steps': 2,\n",
            " 'hidden_size': 768,\n",
            " 'latent_dim': 8,\n",
            " 'latent_dims': [8],\n",
            " 'learning_rates': [0.0005],\n",
            " 'lm_batch_size': 1,\n",
            " 'lr': 0.0005,\n",
            " 'max_seq_len': 1024,\n",
            " 'models': ['distilgpt2'],\n",
            " 'name': 'distilgpt2',\n",
            " 'num_attention_heads': 12,\n",
            " 'num_epochs': 2,\n",
            " 'num_eval_texts': 5,\n",
            " 'num_hidden_layers': 6,\n",
            " 'num_train_texts': 100,\n",
            " 'output_dir': '/content/learned-kv-compression/test_results_distilgpt2/distilgpt2/distilgpt2_latent8_lr0.0005',\n",
            " 'quantization_bits': [4, 8],\n",
            " 'seed': 42,\n",
            " 'skip_training': False,\n",
            " 'vocab_size': 50257}\n",
            "Using dtype: torch.bfloat16\n",
            "tokenizer_config.json: 100% 26.0/26.0 [00:00<00:00, 202kB/s]\n",
            "config.json: 100% 762/762 [00:00<00:00, 5.93MB/s]\n",
            "vocab.json: 100% 1.04M/1.04M [00:00<00:00, 6.78MB/s]\n",
            "merges.txt: 100% 456k/456k [00:00<00:00, 6.09MB/s]\n",
            "tokenizer.json: 100% 1.36M/1.36M [00:00<00:00, 16.2MB/s]\n",
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "model.safetensors: 100% 353M/353M [00:01<00:00, 241MB/s]\n",
            "generation_config.json: 100% 124/124 [00:00<00:00, 1.20MB/s]\n",
            "README.md: 100% 10.5k/10.5k [00:00<00:00, 69.6MB/s]\n",
            "test-00000-of-00001.parquet: 100% 733k/733k [00:00<00:00, 4.70MB/s]\n",
            "train-00000-of-00002.parquet: 100% 157M/157M [00:01<00:00, 141MB/s]\n",
            "train-00001-of-00002.parquet: 100% 157M/157M [00:00<00:00, 208MB/s]\n",
            "validation-00000-of-00001.parquet: 100% 657k/657k [00:00<00:00, 379MB/s]\n",
            "Generating test split: 100% 4358/4358 [00:00<00:00, 120067.11 examples/s]\n",
            "Generating train split: 100% 1801350/1801350 [00:02<00:00, 867864.88 examples/s]\n",
            "Generating validation split: 100% 3760/3760 [00:00<00:00, 558112.43 examples/s]\n",
            "README.md: 100% 16.0k/16.0k [00:00<00:00, 67.1MB/s]\n",
            "LongBench.py: 100% 3.98k/3.98k [00:00<00:00, 35.2MB/s]\n",
            "0000.parquet: 100% 1.31M/1.31M [00:00<00:00, 300MB/s]\n",
            "Generating test split: 100% 200/200 [00:00<00:00, 3344.42 examples/s]\n",
            "0000.parquet: 100% 6.62M/6.62M [00:00<00:00, 124MB/s]\n",
            "Generating test split: 100% 200/200 [00:00<00:00, 3100.29 examples/s]\n",
            "0000.parquet: 100% 3.59M/3.59M [00:00<00:00, 76.3MB/s]\n",
            "Generating test split: 100% 200/200 [00:00<00:00, 6642.92 examples/s]\n",
            "0000.parquet: 100% 8.12M/8.12M [00:00<00:00, 147MB/s]\n",
            "Generating test split: 100% 200/200 [00:00<00:00, 2969.88 examples/s]\n",
            "0000.parquet: 100% 5.17M/5.17M [00:00<00:00, 101MB/s]\n",
            "Generating test split: 100% 200/200 [00:00<00:00, 4504.63 examples/s]\n",
            "Buffer using data type: torch.bfloat16\n",
            "Using buffer sequence length of 256 tokens (max_seq_len: 1024, buffer_size: 256)\n",
            "Allocating buffers with shape (64, 6, 12, 256, 64), total elements: 75497472\n",
            "Buffer using data type: torch.bfloat16\n",
            "Using buffer sequence length of 256 tokens (max_seq_len: 1024, buffer_size: 256)\n",
            "Allocating buffers with shape (64, 6, 12, 256, 64), total elements: 75497472\n",
            "Epoch 1/2: 100% 1/1 [00:00<00:00,  1.05it/s]\n",
            "Epoch 1, Loss: 0.1357\n",
            "Saved /content/learned-kv-compression/test_results_distilgpt2/distilgpt2/distilgpt2_latent8_lr0.0005/autoencoders_epoch_1.pth\n",
            "Epoch 2/2: 100% 1/1 [00:00<00:00,  1.56it/s]\n",
            "Epoch 2, Loss: 0.1768\n",
            "Saved /content/learned-kv-compression/test_results_distilgpt2/distilgpt2/distilgpt2_latent8_lr0.0005/autoencoders_epoch_2.pth\n",
            "Saved final autoencoder checkpoint to: /content/learned-kv-compression/test_results_distilgpt2/distilgpt2/distilgpt2_latent8_lr0.0005/autoencoders_final.pth\n",
            "Training complete!\n",
            "Training finished for distilgpt2_latent8_lr0.0005_epochs2_texts100. Checking for model file...\n",
            "Running check: ls -l /content/learned-kv-compression/test_results_distilgpt2/distilgpt2/distilgpt2_latent8_lr0.0005/autoencoders_final.pth\n",
            "-rw-r--r-- 1 root root 22082 Apr 24 00:36 /content/learned-kv-compression/test_results_distilgpt2/distilgpt2/distilgpt2_latent8_lr0.0005/autoencoders_final.pth\n",
            "\n",
            "================================================================================\n",
            "Running benchmark with model=distilgpt2, latent_dim=8, batch_size=64, num_runs=5\n",
            "================================================================================\n",
            "python -m src.inference.benchmark --config /content/learned-kv-compression/test_results_distilgpt2/distilgpt2/benchmark_distilgpt2_latent8_lr0.0005_quant4_batch64_runs5/benchmark_config.json\n",
            "2025-04-24 00:36:46.970521: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-04-24 00:36:46.988873: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1745455007.010577    2115 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1745455007.017315    2115 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-04-24 00:36:47.039471: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:820: UserWarning: `return_dict_in_generate` is NOT set to `True`, but `output_attentions` is. When `return_dict_in_generate` is not `True`, `output_attentions` is ignored.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:820: UserWarning: `return_dict_in_generate` is NOT set to `True`, but `output_hidden_states` is. When `return_dict_in_generate` is not `True`, `output_hidden_states` is ignored.\n",
            "  warnings.warn(\n",
            "Eval quantized KV baseline:   0% 0/5 [00:00<?, ?it/s]`torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True`. Falling back to eager attention. This warning can be removed using the argument `attn_implementation=\"eager\"` when loading the model.\n",
            "Eval quantized KV baseline: 100% 5/5 [00:03<00:00,  1.38it/s]\n",
            "Eval compressed: 100% 5/5 [00:03<00:00,  1.33it/s]\n",
            "Calculating perplexity (narrativeqa): 100% 5/5 [00:00<00:00, 86.60it/s]\n",
            "Eval compressed: 100% 5/5 [00:00<00:00, 11.67it/s]\n",
            "Calculating perplexity (hotpotqa): 100% 5/5 [00:00<00:00, 84.25it/s]\n",
            "Eval compressed: 100% 5/5 [00:01<00:00,  4.82it/s]\n",
            "Calculating perplexity (2wikimqa): 100% 5/5 [00:00<00:00, 132.22it/s]\n",
            "Eval compressed: 100% 5/5 [00:00<00:00,  6.53it/s]\n",
            "Calculating perplexity (musique): 100% 5/5 [00:00<00:00, 131.70it/s]\n",
            "Eval compressed: 100% 5/5 [00:00<00:00,  5.79it/s]\n",
            "Calculating perplexity (dureader): 100% 5/5 [00:00<00:00, 133.16it/s]\n",
            "Eval compressed: 100% 5/5 [00:00<00:00,  5.18it/s]\n",
            "Saved benchmark results to /content/learned-kv-compression/test_results_distilgpt2/distilgpt2/benchmark_distilgpt2_latent8_lr0.0005_quant4_batch64_runs5/benchmark_results.json\n",
            "Baseline perplexity: 95.94\n",
            "Compressed perplexity: 5100.85\n",
            "LongBench results:\n",
            "  narrativeqa: baseline=385.89, compressed=6065.01\n",
            "  hotpotqa: baseline=231.47, compressed=4362.34\n",
            "  2wikimqa: baseline=376.63, compressed=4544.68\n",
            "  musique: baseline=185.35, compressed=2185.94\n",
            "  dureader: baseline=83.78, compressed=4722.38\n",
            "\n",
            "================================================================================\n",
            "Running benchmark with model=distilgpt2, latent_dim=8, batch_size=64, num_runs=5\n",
            "================================================================================\n",
            "python -m src.inference.benchmark --config /content/learned-kv-compression/test_results_distilgpt2/distilgpt2/benchmark_distilgpt2_latent8_lr0.0005_quant8_batch64_runs5/benchmark_config.json\n",
            "2025-04-24 00:37:16.787720: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-04-24 00:37:16.804919: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1745455036.826034    2319 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1745455036.832477    2319 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-04-24 00:37:16.853101: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:820: UserWarning: `return_dict_in_generate` is NOT set to `True`, but `output_attentions` is. When `return_dict_in_generate` is not `True`, `output_attentions` is ignored.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:820: UserWarning: `return_dict_in_generate` is NOT set to `True`, but `output_hidden_states` is. When `return_dict_in_generate` is not `True`, `output_hidden_states` is ignored.\n",
            "  warnings.warn(\n",
            "Eval quantized KV baseline:   0% 0/5 [00:00<?, ?it/s]`torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True`. Falling back to eager attention. This warning can be removed using the argument `attn_implementation=\"eager\"` when loading the model.\n",
            "Eval quantized KV baseline: 100% 5/5 [00:03<00:00,  1.41it/s]\n",
            "Eval compressed: 100% 5/5 [00:03<00:00,  1.33it/s]\n",
            "Calculating perplexity (narrativeqa): 100% 5/5 [00:00<00:00, 86.48it/s]\n",
            "Eval compressed: 100% 5/5 [00:00<00:00, 11.70it/s]\n",
            "Calculating perplexity (hotpotqa): 100% 5/5 [00:00<00:00, 82.46it/s]\n",
            "Eval compressed: 100% 5/5 [00:01<00:00,  4.87it/s]\n",
            "Calculating perplexity (2wikimqa): 100% 5/5 [00:00<00:00, 131.40it/s]\n",
            "Eval compressed: 100% 5/5 [00:00<00:00,  6.59it/s]\n",
            "Calculating perplexity (musique): 100% 5/5 [00:00<00:00, 134.28it/s]\n",
            "Eval compressed: 100% 5/5 [00:00<00:00,  5.86it/s]\n",
            "Calculating perplexity (dureader): 100% 5/5 [00:00<00:00, 134.61it/s]\n",
            "Eval compressed: 100% 5/5 [00:00<00:00,  5.21it/s]\n",
            "Saved benchmark results to /content/learned-kv-compression/test_results_distilgpt2/distilgpt2/benchmark_distilgpt2_latent8_lr0.0005_quant8_batch64_runs5/benchmark_results.json\n",
            "Baseline perplexity: 72.83\n",
            "Compressed perplexity: 4870.93\n",
            "LongBench results:\n",
            "  narrativeqa: baseline=385.89, compressed=5936.23\n",
            "  hotpotqa: baseline=231.47, compressed=4352.35\n",
            "  2wikimqa: baseline=376.63, compressed=4563.36\n",
            "  musique: baseline=185.35, compressed=2101.38\n",
            "  dureader: baseline=83.78, compressed=4830.44\n",
            "\n",
            "================================================================================\n",
            "Experiment Summary\n",
            "================================================================================\n",
            "Models tested: ['distilgpt2']\n",
            "Latent dimensions tested: [8]\n",
            "Learning rates tested: [0.0005]\n",
            "Quantization bits tested: [4, 8]\n",
            "Epochs tested: [2]\n",
            "Training texts tested: [100]\n",
            "Batch sizes tested: [64]\n",
            "Number of runs tested: [5]\n",
            "KV cache sizes tested: [1, 10, 100, 1000] MB\n",
            "Total runtime: 0h 1m 49.34s\n",
            "Results saved to: /content/learned-kv-compression/test_results_distilgpt2\n",
            "Total experiments: 2\n",
            "================================================================================\n",
            "Experiment Results:\n",
            "- Model: distilgpt2, Latent dim: 8, Cache sizes: [1, 10, 100, 1000] MB, LR: 0.0005, Epochs: 2, Texts: 100, Quantization bits: 4, Batch: 64, Runs: 5\n",
            "  Result dir: /content/learned-kv-compression/test_results_distilgpt2/distilgpt2/benchmark_distilgpt2_latent8_lr0.0005_quant4_batch64_runs5\n",
            "- Model: distilgpt2, Latent dim: 8, Cache sizes: [1, 10, 100, 1000] MB, LR: 0.0005, Epochs: 2, Texts: 100, Quantization bits: 8, Batch: 64, Runs: 5\n",
            "  Result dir: /content/learned-kv-compression/test_results_distilgpt2/distilgpt2/benchmark_distilgpt2_latent8_lr0.0005_quant8_batch64_runs5\n",
            "================================================================================\n",
            "Experiment completed at Thu Apr 24 12:37:43 AM UTC 2025\n",
            "Generating comparison report...\n",
            "Looking for summary file at: /content/learned-kv-compression/test_results_distilgpt2/experiment_summary.json\n",
            "Using experiment summary to find result directories\n",
            "Found result directories: /content/learned-kv-compression/test_results_distilgpt2/distilgpt2/benchmark_distilgpt2_latent8_lr0.0005_quant4_batch64_runs5 /content/learned-kv-compression/test_results_distilgpt2/distilgpt2/benchmark_distilgpt2_latent8_lr0.0005_quant8_batch64_runs5\n",
            "Loading results from: ['/content/learned-kv-compression/test_results_distilgpt2/distilgpt2/benchmark_distilgpt2_latent8_lr0.0005_quant4_batch64_runs5', '/content/learned-kv-compression/test_results_distilgpt2/distilgpt2/benchmark_distilgpt2_latent8_lr0.0005_quant8_batch64_runs5']\n",
            "Generating comparison plots...\n",
            "Warning: No valid cache_size_mb values; skipping time comparison plot.\n",
            "Warning: Compression ratio data not available\n",
            "Warning: No valid cache_size_mb values; skipping speedup plot.\n",
            "Warning: Speedup or compression ratio data not available\n",
            "Generating summary report...\n",
            "Report generated at /content/learned-kv-compression/test_results_distilgpt2/comparison/comparison_report.md\n",
            "Comparison complete. Results saved to /content/learned-kv-compression/test_results_distilgpt2/comparison\n",
            "Comparison analysis complete!\n",
            "Experiment and analysis complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "PMANLyemhaTB"
      },
      "outputs": [],
      "source": [
        "#!./run_experiments.sh configs/qwen25_0.5b_test.json"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}