{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ta6KkToOAF1M"
      },
      "source": [
        "# Notebook to run learned kv compression scripts on colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prGnb-vKAnzs"
      },
      "source": [
        "Download Repo and Install Requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YbnT8hMBAE49",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "# Download Repo\n",
        "%cd /content\n",
        "!rm -rf learned-kv-compression\n",
        "!git clone -b colab https://henro25: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@github.com/henro25/learned-kv-compression\n",
        "%cd /content/learned-kv-compression/\n",
        "%ls\n",
        "\n",
        "# Install Requirements\n",
        "%pip install -r colab_requirements.txt\n",
        "%pip uninstall gcsfs -y\n",
        "%pip install --upgrade fsspec==2025.3.2\n",
        "%pip install gcsfs==2024.12.0\n",
        "%pip install --upgrade datasets\n",
        "\n",
        "!apt-get update -y\n",
        "!apt-get install -y jq\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "# Enable permissions if needed\n",
        "!chmod +x run_experiments.sh"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and Benchmarking"
      ],
      "metadata": {
        "id": "j0OAZB07jbwR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# Reload Repo\n",
        "%cd /content\n",
        "!rm -rf learned-kv-compression\n",
        "!git clone -b colab https://henro25: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@github.com/henro25/learned-kv-compression\n",
        "%cd /content/learned-kv-compression/\n",
        "%ls"
      ],
      "metadata": {
        "id": "RjZuU_MKjldD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run distilgpt2 training latent = 32\n",
        "!python -m src.dictionary_learning.train --config configs/distilgpt2_experiment_32.json"
      ],
      "metadata": {
        "id": "hPte3K8Hjkek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run distilgpt2 benchmarking latent = 32\n",
        "!python -m src.inference.benchmark \\\n",
        "    --config configs/distilgpt2_experiment_32.json"
      ],
      "metadata": {
        "id": "Dn5eH1mljtwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Distilgpt2 Test"
      ],
      "metadata": {
        "id": "53smQpKCQjDy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !./run_experiments.sh configs/distilgpt2_test.json"
      ],
      "metadata": {
        "collapsed": true,
        "id": "U7pL1VbTNWy0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !zip -r test_results_distilgpt2.zip test_results_distilgpt2\n",
        "# files.download('test_results_distilgpt2.zip')"
      ],
      "metadata": {
        "id": "Ns4EzLboQaUG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Distilgpt2 Experiment"
      ],
      "metadata": {
        "id": "vr3uFia_QmSH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!./run_experiments.sh configs/distilgpt2_experiment.json"
      ],
      "metadata": {
        "id": "3AAGcBw1QGXY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r experiment_results_distilgpt2.zip experiment_results_distilgpt2\n",
        "files.download('experiment_results_distilgpt2.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Ccky5bMNGUna",
        "outputId": "4978f9d6-3bb1-4be3-f80e-c3f4f0632cb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: experiment_results_distilgpt2/ (stored 0%)\n",
            "  adding: experiment_results_distilgpt2/experiment_summary.json (deflated 89%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2/ (stored 0%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2/distilgpt2_latent32_lr0.0005/ (stored 0%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2/distilgpt2_latent32_lr0.0005/autoencoders_final.pth (deflated 34%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2/distilgpt2_latent32_lr0.0005/autoencoders_epoch_10.pth (deflated 34%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2/distilgpt2_latent32_lr0.0005/attention_viz/ (stored 0%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2/distilgpt2_latent32_lr0.0005/train_config.json (deflated 53%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2/distilgpt2_latent32_lr0.0005/autoencoders_epoch_5.pth (deflated 33%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2/benchmark_distilgpt2_latent16_lr0.0005_quant4_batch64_runs5/ (stored 0%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2/benchmark_distilgpt2_latent16_lr0.0005_quant4_batch64_runs5/benchmark_config.json (deflated 58%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2/benchmark_distilgpt2_latent16_lr0.0005_quant4_batch64_runs5/benchmark_results.json (deflated 69%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2/distilgpt2_latent16_lr0.0005/ (stored 0%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2/distilgpt2_latent16_lr0.0005/autoencoders_final.pth (deflated 38%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2/distilgpt2_latent16_lr0.0005/autoencoders_epoch_10.pth (deflated 39%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2/distilgpt2_latent16_lr0.0005/attention_viz/ (stored 0%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2/distilgpt2_latent16_lr0.0005/train_config.json (deflated 53%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2/distilgpt2_latent16_lr0.0005/autoencoders_epoch_5.pth (deflated 38%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2/benchmark_distilgpt2_latent16_lr0.0005_quant2_batch64_runs5/ (stored 0%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2/benchmark_distilgpt2_latent16_lr0.0005_quant2_batch64_runs5/benchmark_config.json (deflated 58%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2/benchmark_distilgpt2_latent16_lr0.0005_quant2_batch64_runs5/benchmark_results.json (deflated 69%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2/benchmark_distilgpt2_latent32_lr0.0005_quant8_batch64_runs5/ (stored 0%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2/benchmark_distilgpt2_latent32_lr0.0005_quant8_batch64_runs5/benchmark_config.json (deflated 58%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2/benchmark_distilgpt2_latent32_lr0.0005_quant8_batch64_runs5/benchmark_results.json (deflated 68%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2/benchmark_distilgpt2_latent16_lr0.0005_quant8_batch64_runs5/ (stored 0%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2/benchmark_distilgpt2_latent16_lr0.0005_quant8_batch64_runs5/benchmark_config.json (deflated 58%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2/benchmark_distilgpt2_latent16_lr0.0005_quant8_batch64_runs5/benchmark_results.json (deflated 69%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2/distilgpt2_latent16_lr0.0005_epochs10_texts50000/ (stored 0%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2/benchmark_distilgpt2_latent16_lr0.0005_quant16_batch64_runs5/ (stored 0%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2/benchmark_distilgpt2_latent16_lr0.0005_quant16_batch64_runs5/benchmark_config.json (deflated 58%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2/benchmark_distilgpt2_latent16_lr0.0005_quant16_batch64_runs5/benchmark_results.json (deflated 68%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2/benchmark_distilgpt2_latent32_lr0.0005_quant4_batch64_runs5/ (stored 0%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2/benchmark_distilgpt2_latent32_lr0.0005_quant4_batch64_runs5/benchmark_config.json (deflated 58%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2/benchmark_distilgpt2_latent32_lr0.0005_quant4_batch64_runs5/benchmark_results.json (deflated 68%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2/benchmark_distilgpt2_latent32_lr0.0005_quant16_batch64_runs5/ (stored 0%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2/benchmark_distilgpt2_latent32_lr0.0005_quant16_batch64_runs5/benchmark_config.json (deflated 58%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2/benchmark_distilgpt2_latent32_lr0.0005_quant16_batch64_runs5/benchmark_results.json (deflated 68%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2/benchmark_distilgpt2_latent32_lr0.0005_quant2_batch64_runs5/ (stored 0%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2/benchmark_distilgpt2_latent32_lr0.0005_quant2_batch64_runs5/benchmark_config.json (deflated 58%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2/benchmark_distilgpt2_latent32_lr0.0005_quant2_batch64_runs5/benchmark_results.json (deflated 69%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2/distilgpt2_latent32_lr0.0005_epochs10_texts50000/ (stored 0%)\n",
            "  adding: experiment_results_distilgpt2/experiment_summary.txt (deflated 42%)\n",
            "  adding: experiment_results_distilgpt2/benchmark_distilgpt2_latent1_batch65_runs1/ (stored 0%)\n",
            "  adding: experiment_results_distilgpt2/benchmark_distilgpt2_latent1_batch65_runs1/benchmark_config.json (deflated 49%)\n",
            "  adding: experiment_results_distilgpt2/benchmark_distilgpt2_latent8/ (stored 0%)\n",
            "  adding: experiment_results_distilgpt2/benchmark_distilgpt2_latent8/compression_ratio.png (deflated 42%)\n",
            "  adding: experiment_results_distilgpt2/benchmark_distilgpt2_latent8/benchmark_distilgpt2_latent8/ (stored 0%)\n",
            "  adding: experiment_results_distilgpt2/benchmark_distilgpt2_latent8/benchmark_distilgpt2_latent8/evaluation_results.json (deflated 55%)\n",
            "  adding: experiment_results_distilgpt2/benchmark_distilgpt2_latent8/benchmark_distilgpt2_latent8/evaluation_results.csv (deflated 40%)\n",
            "  adding: experiment_results_distilgpt2/benchmark_distilgpt2_latent8/benchmark_distilgpt2_latent8/plots/ (stored 0%)\n",
            "  adding: experiment_results_distilgpt2/benchmark_distilgpt2_latent8/benchmark_distilgpt2_latent8/plots/perplexity_ratio_heatmap.png (deflated 18%)\n",
            "  adding: experiment_results_distilgpt2/benchmark_distilgpt2_latent8/benchmark_distilgpt2_latent8/plots/performance_degradation.png (deflated 20%)\n",
            "  adding: experiment_results_distilgpt2/benchmark_distilgpt2_latent8/benchmark_distilgpt2_latent8/plots/perplexity_comparison.png (deflated 20%)\n",
            "  adding: experiment_results_distilgpt2/benchmark_distilgpt2_latent8/time_comparison.png (deflated 22%)\n",
            "  adding: experiment_results_distilgpt2/benchmark_distilgpt2_latent8/.DS_Store (deflated 96%)\n",
            "  adding: experiment_results_distilgpt2/benchmark_distilgpt2_latent8/speedup.png (deflated 23%)\n",
            "  adding: experiment_results_distilgpt2/benchmark_distilgpt2_latent8/benchmark_config.json (deflated 50%)\n",
            "  adding: experiment_results_distilgpt2/benchmark_distilgpt2_latent8/benchmark_results.json (deflated 95%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2_latent16/ (stored 0%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2_latent16/train_config.json (deflated 47%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2_latent16/autoencoder_config.json (deflated 52%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2_latent8/ (stored 0%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2_latent8/attention_viz/ (stored 0%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2_latent8/attention_viz/epoch_1_batch_2400_layer_0_head_0.png (deflated 1%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2_latent8/attention_viz/epoch_5_batch_900_layer_0_head_0.png (deflated 1%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2_latent8/attention_viz/epoch_1_batch_1200_layer_0_head_0.png (deflated 1%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2_latent8/attention_viz/epoch_1_batch_3300_layer_0_head_0.png (deflated 1%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2_latent8/attention_viz/epoch_1_batch_100_layer_0_head_0.png (deflated 1%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2_latent8/attention_viz/epoch_1_batch_2200_layer_0_head_0.png (deflated 1%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2_latent8/attention_viz/epoch_1_batch_1100_layer_0_head_0.png (deflated 1%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2_latent8/attention_viz/epoch_1_batch_3200_layer_0_head_0.png (deflated 1%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2_latent8/attention_viz/epoch_1_batch_1900_layer_0_head_0.png (deflated 1%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2_latent8/attention_viz/epoch_1_batch_0_layer_0_head_0.png (deflated 1%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2_latent8/attention_viz/epoch_1_batch_2100_layer_0_head_0.png (deflated 1%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2_latent8/attention_viz/epoch_1_batch_1800_layer_0_head_0.png (deflated 1%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2_latent8/attention_viz/epoch_1_batch_300_layer_0_head_0.png (deflated 1%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2_latent8/attention_viz/epoch_1_batch_2800_layer_0_head_0.png (deflated 1%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2_latent8/attention_viz/epoch_1_batch_3000_layer_0_head_0.png (deflated 1%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2_latent8/attention_viz/epoch_1_batch_3700_layer_0_head_0.png (deflated 1%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2_latent8/attention_viz/epoch_1_batch_2300_layer_0_head_0.png (deflated 1%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2_latent8/attention_viz/epoch_1_batch_2600_layer_0_head_0.png (deflated 1%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2_latent8/attention_viz/epoch_1_batch_1400_layer_0_head_0.png (deflated 1%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2_latent8/attention_viz/epoch_1_batch_1700_layer_0_head_0.png (deflated 1%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2_latent8/attention_viz/epoch_1_batch_1300_layer_0_head_0.png (deflated 1%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2_latent8/attention_viz/epoch_1_batch_2500_layer_0_head_0.png (deflated 1%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2_latent8/attention_viz/epoch_1_batch_1600_layer_0_head_0.png (deflated 1%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2_latent8/attention_viz/epoch_1_batch_1500_layer_0_head_0.png (deflated 1%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2_latent8/attention_viz/epoch_1_batch_2900_layer_0_head_0.png (deflated 1%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2_latent8/attention_viz/epoch_1_batch_3800_layer_0_head_0.png (deflated 1%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2_latent8/attention_viz/epoch_1_batch_2000_layer_0_head_0.png (deflated 1%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2_latent8/attention_viz/epoch_1_batch_3100_layer_0_head_0.png (deflated 1%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2_latent8/attention_viz/epoch_1_batch_3400_layer_0_head_0.png (deflated 1%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2_latent8/attention_viz/epoch_1_batch_3600_layer_0_head_0.png (deflated 1%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2_latent8/attention_viz/epoch_1_batch_200_layer_0_head_0.png (deflated 1%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2_latent8/attention_viz/epoch_1_batch_1000_layer_0_head_0.png (deflated 1%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2_latent8/attention_viz/epoch_1_batch_3900_layer_0_head_0.png (deflated 1%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2_latent8/attention_viz/epoch_1_batch_2700_layer_0_head_0.png (deflated 1%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2_latent8/attention_viz/epoch_1_batch_3500_layer_0_head_0.png (deflated 1%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2_latent8/train_config.json (deflated 47%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2_latent8/autoencoder_config.json (deflated 52%)\n",
            "  adding: experiment_results_distilgpt2/.DS_Store (deflated 96%)\n",
            "  adding: experiment_results_distilgpt2/benchmark_distilgpt2_latent1_batch64_runs1/ (stored 0%)\n",
            "  adding: experiment_results_distilgpt2/benchmark_distilgpt2_latent1_batch64_runs1/benchmark_distilgpt2_latent1/ (stored 0%)\n",
            "  adding: experiment_results_distilgpt2/benchmark_distilgpt2_latent1_batch64_runs1/benchmark_distilgpt2_latent1/evaluation_results.json (deflated 54%)\n",
            "  adding: experiment_results_distilgpt2/benchmark_distilgpt2_latent1_batch64_runs1/benchmark_distilgpt2_latent1/evaluation_results.csv (deflated 39%)\n",
            "  adding: experiment_results_distilgpt2/benchmark_distilgpt2_latent1_batch64_runs1/benchmark_distilgpt2_latent1/plots/ (stored 0%)\n",
            "  adding: experiment_results_distilgpt2/benchmark_distilgpt2_latent1_batch64_runs1/benchmark_distilgpt2_latent1/plots/perplexity_ratio_heatmap.png (deflated 17%)\n",
            "  adding: experiment_results_distilgpt2/benchmark_distilgpt2_latent1_batch64_runs1/benchmark_distilgpt2_latent1/plots/performance_degradation.png (deflated 21%)\n",
            "  adding: experiment_results_distilgpt2/benchmark_distilgpt2_latent1_batch64_runs1/benchmark_distilgpt2_latent1/plots/perplexity_comparison.png (deflated 21%)\n",
            "  adding: experiment_results_distilgpt2/benchmark_distilgpt2_latent1_batch64_runs1/benchmark_config.json (deflated 49%)\n",
            "  adding: experiment_results_distilgpt2/benchmark_distilgpt2_latent16/ (stored 0%)\n",
            "  adding: experiment_results_distilgpt2/benchmark_distilgpt2_latent16/compression_ratio.png (deflated 40%)\n",
            "  adding: experiment_results_distilgpt2/benchmark_distilgpt2_latent16/time_comparison.png (deflated 23%)\n",
            "  adding: experiment_results_distilgpt2/benchmark_distilgpt2_latent16/benchmark_distilgpt2_latent16/ (stored 0%)\n",
            "  adding: experiment_results_distilgpt2/benchmark_distilgpt2_latent16/benchmark_distilgpt2_latent16/evaluation_results.json (deflated 55%)\n",
            "  adding: experiment_results_distilgpt2/benchmark_distilgpt2_latent16/benchmark_distilgpt2_latent16/evaluation_results.csv (deflated 41%)\n",
            "  adding: experiment_results_distilgpt2/benchmark_distilgpt2_latent16/benchmark_distilgpt2_latent16/plots/ (stored 0%)\n",
            "  adding: experiment_results_distilgpt2/benchmark_distilgpt2_latent16/benchmark_distilgpt2_latent16/plots/perplexity_ratio_heatmap.png (deflated 17%)\n",
            "  adding: experiment_results_distilgpt2/benchmark_distilgpt2_latent16/benchmark_distilgpt2_latent16/plots/performance_degradation.png (deflated 20%)\n",
            "  adding: experiment_results_distilgpt2/benchmark_distilgpt2_latent16/benchmark_distilgpt2_latent16/plots/perplexity_comparison.png (deflated 20%)\n",
            "  adding: experiment_results_distilgpt2/benchmark_distilgpt2_latent16/speedup.png (deflated 23%)\n",
            "  adding: experiment_results_distilgpt2/benchmark_distilgpt2_latent16/benchmark_config.json (deflated 50%)\n",
            "  adding: experiment_results_distilgpt2/benchmark_distilgpt2_latent16/benchmark_results.json (deflated 95%)\n",
            "  adding: experiment_results_distilgpt2/benchmark_distilgpt2_latent1_batch64_runs3/ (stored 0%)\n",
            "  adding: experiment_results_distilgpt2/benchmark_distilgpt2_latent1_batch64_runs3/benchmark_config.json (deflated 49%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2_latent32/ (stored 0%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2_latent32/train_config.json (deflated 47%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2_latent32/autoencoder_config.json (deflated 52%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2_latent1/ (stored 0%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2_latent1/attention_viz/ (stored 0%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2_latent1/attention_viz/epoch_1_batch_0_layer_0_head_0.png (deflated 6%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2_latent1/train_config.json (deflated 48%)\n",
            "  adding: experiment_results_distilgpt2/distilgpt2_latent1/autoencoder_config.json (deflated 53%)\n",
            "  adding: experiment_results_distilgpt2/benchmark_distilgpt2_latent1_batch64_runs2/ (stored 0%)\n",
            "  adding: experiment_results_distilgpt2/benchmark_distilgpt2_latent1_batch64_runs2/benchmark_distilgpt2_latent1/ (stored 0%)\n",
            "  adding: experiment_results_distilgpt2/benchmark_distilgpt2_latent1_batch64_runs2/benchmark_distilgpt2_latent1/evaluation_results.json (deflated 54%)\n",
            "  adding: experiment_results_distilgpt2/benchmark_distilgpt2_latent1_batch64_runs2/benchmark_distilgpt2_latent1/evaluation_results.csv (deflated 39%)\n",
            "  adding: experiment_results_distilgpt2/benchmark_distilgpt2_latent1_batch64_runs2/benchmark_distilgpt2_latent1/plots/ (stored 0%)\n",
            "  adding: experiment_results_distilgpt2/benchmark_distilgpt2_latent1_batch64_runs2/benchmark_distilgpt2_latent1/plots/perplexity_ratio_heatmap.png (deflated 17%)\n",
            "  adding: experiment_results_distilgpt2/benchmark_distilgpt2_latent1_batch64_runs2/benchmark_distilgpt2_latent1/plots/performance_degradation.png (deflated 21%)\n",
            "  adding: experiment_results_distilgpt2/benchmark_distilgpt2_latent1_batch64_runs2/benchmark_distilgpt2_latent1/plots/perplexity_comparison.png (deflated 21%)\n",
            "  adding: experiment_results_distilgpt2/benchmark_distilgpt2_latent1_batch64_runs2/benchmark_config.json (deflated 49%)\n",
            "  adding: experiment_results_distilgpt2/benchmark_distilgpt2_latent32/ (stored 0%)\n",
            "  adding: experiment_results_distilgpt2/benchmark_distilgpt2_latent32/compression_ratio.png (deflated 40%)\n",
            "  adding: experiment_results_distilgpt2/benchmark_distilgpt2_latent32/time_comparison.png (deflated 22%)\n",
            "  adding: experiment_results_distilgpt2/benchmark_distilgpt2_latent32/speedup.png (deflated 27%)\n",
            "  adding: experiment_results_distilgpt2/benchmark_distilgpt2_latent32/benchmark_config.json (deflated 50%)\n",
            "  adding: experiment_results_distilgpt2/benchmark_distilgpt2_latent32/benchmark_distilgpt2_latent32/ (stored 0%)\n",
            "  adding: experiment_results_distilgpt2/benchmark_distilgpt2_latent32/benchmark_distilgpt2_latent32/evaluation_results.json (deflated 55%)\n",
            "  adding: experiment_results_distilgpt2/benchmark_distilgpt2_latent32/benchmark_distilgpt2_latent32/evaluation_results.csv (deflated 41%)\n",
            "  adding: experiment_results_distilgpt2/benchmark_distilgpt2_latent32/benchmark_distilgpt2_latent32/plots/ (stored 0%)\n",
            "  adding: experiment_results_distilgpt2/benchmark_distilgpt2_latent32/benchmark_distilgpt2_latent32/plots/perplexity_ratio_heatmap.png (deflated 17%)\n",
            "  adding: experiment_results_distilgpt2/benchmark_distilgpt2_latent32/benchmark_distilgpt2_latent32/plots/performance_degradation.png (deflated 21%)\n",
            "  adding: experiment_results_distilgpt2/benchmark_distilgpt2_latent32/benchmark_distilgpt2_latent32/plots/perplexity_comparison.png (deflated 20%)\n",
            "  adding: experiment_results_distilgpt2/benchmark_distilgpt2_latent32/benchmark_results.json (deflated 95%)\n",
            "  adding: experiment_results_distilgpt2/comparison/ (stored 0%)\n",
            "  adding: experiment_results_distilgpt2/comparison/tradeoff.png (deflated 23%)\n",
            "  adding: experiment_results_distilgpt2/comparison/compression_ratio.png (deflated 22%)\n",
            "  adding: experiment_results_distilgpt2/comparison/time_comparison.png (deflated 26%)\n",
            "  adding: experiment_results_distilgpt2/comparison/bar_compression_ratio.png (deflated 31%)\n",
            "  adding: experiment_results_distilgpt2/comparison/speedup_multiple_latent_dim.png (deflated 22%)\n",
            "  adding: experiment_results_distilgpt2/comparison/speedup_heatmap.png (deflated 29%)\n",
            "  adding: experiment_results_distilgpt2/comparison/speedup.png (deflated 24%)\n",
            "  adding: experiment_results_distilgpt2/comparison/time_comparison_multiple_latent_dim.png (deflated 21%)\n",
            "  adding: experiment_results_distilgpt2/comparison/comparison_report.md (deflated 61%)\n",
            "  adding: experiment_results_distilgpt2/comparison/bar_comparison_largest.png (deflated 26%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f4316696-e5ee-4ba4-806a-fb8a0fe64e8f\", \"experiment_results_distilgpt2.zip\", 21386260)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Qwen2.5 0.5b Test"
      ],
      "metadata": {
        "id": "lQvonSLlQpEp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PMANLyemhaTB",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# !./run_experiments.sh configs/qwen25_0.5b_test.json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !zip -r test_results_Qwen.zip test_results_Qwen\n",
        "# files.download('test_results_Qwen.zip')"
      ],
      "metadata": {
        "id": "3NOPBHVlQWqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Qwen2.5 0.5b Experiment"
      ],
      "metadata": {
        "id": "cbiAd6nqQs-I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!./run_experiments.sh configs/qwen25_0.5b_experiment.json"
      ],
      "metadata": {
        "id": "Ie6SsRANQKFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r experiment_results_Qwen.zip experiment_results_Qwen\n",
        "files.download('experiment_results_Qwen.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BxFW0qqSvCIo",
        "outputId": "aa972bf8-cdef-4c1a-d0a2-3924ba9be1b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "updating: experiment_results_Qwen/ (stored 0%)\n",
            "updating: experiment_results_Qwen/comparison/ (stored 0%)\n",
            "updating: experiment_results_Qwen/comparison/bar_compression_ratio.png (deflated 32%)\n",
            "updating: experiment_results_Qwen/comparison/time_comparison.png (deflated 30%)\n",
            "updating: experiment_results_Qwen/comparison/speedup_heatmap.png (deflated 32%)\n",
            "updating: experiment_results_Qwen/comparison/bar_comparison_largest.png (deflated 31%)\n",
            "updating: experiment_results_Qwen/comparison/speedup.png (deflated 27%)\n",
            "updating: experiment_results_Qwen/comparison/comparison_report.md (deflated 56%)\n",
            "updating: experiment_results_Qwen/comparison/compression_ratio.png (deflated 28%)\n",
            "updating: experiment_results_Qwen/comparison/tradeoff.png (deflated 25%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-1.5B/ (stored 0%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-1.5B/Qwen_Qwen2.5-1.5B_latent8_lr0.0001/ (stored 0%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-1.5B/Qwen_Qwen2.5-1.5B_latent8_lr0.0001/train_config.json (deflated 53%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-1.5B/Qwen_Qwen2.5-1.5B_latent8_lr0.001/ (stored 0%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-1.5B/Qwen_Qwen2.5-1.5B_latent8_lr0.001/attention_viz/ (stored 0%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-1.5B/Qwen_Qwen2.5-1.5B_latent8_lr0.001/attention_viz/epoch_1_batch_0_layer_0_head_0.png (deflated 18%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-1.5B/Qwen_Qwen2.5-1.5B_latent8_lr0.001/train_config.json (deflated 53%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-1.5B/benchmark_Qwen_Qwen2.5-1.5B_latent8_lr0.0005_batch64_runs5/ (stored 0%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-1.5B/benchmark_Qwen_Qwen2.5-1.5B_latent8_lr0.0005_batch64_runs5/benchmark_config.json (deflated 58%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-1.5B/benchmark_Qwen_Qwen2.5-1.5B_latent8_lr0.0001_batch64_runs5/ (stored 0%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-1.5B/benchmark_Qwen_Qwen2.5-1.5B_latent8_lr0.0001_batch64_runs5/benchmark_config.json (deflated 59%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-1.5B/benchmark_Qwen_Qwen2.5-1.5B_latent8_lr0.001_batch64_runs5/ (stored 0%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-1.5B/benchmark_Qwen_Qwen2.5-1.5B_latent8_lr0.001_batch64_runs5/benchmark_config.json (deflated 58%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-1.5B/Qwen_Qwen2.5-1.5B_latent8_lr0.0005/ (stored 0%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-1.5B/Qwen_Qwen2.5-1.5B_latent8_lr0.0005/train_config.json (deflated 53%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-0.5B/ (stored 0%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-0.5B/Qwen_Qwen2.5-0.5B_latent8_lr0.0005/ (stored 0%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-0.5B/Qwen_Qwen2.5-0.5B_latent8_lr0.0005/attention_viz/ (stored 0%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-0.5B/Qwen_Qwen2.5-0.5B_latent8_lr0.0005/autoencoders_final.pth (deflated 45%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-0.5B/Qwen_Qwen2.5-0.5B_latent8_lr0.0005/train_config.json (deflated 52%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-0.5B/Qwen_Qwen2.5-0.5B_latent8_lr0.0005/autoencoders_epoch_5.pth (deflated 45%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-0.5B/Qwen_Qwen2.5-0.5B_latent8_lr0.0005_epochs5_texts10000/ (stored 0%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-0.5B/benchmark_Qwen_Qwen2.5-0.5B_latent8_lr0.0005_quant16_batch64_runs5/ (stored 0%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-0.5B/benchmark_Qwen_Qwen2.5-0.5B_latent8_lr0.0005_quant16_batch64_runs5/benchmark_results.json (deflated 68%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-0.5B/benchmark_Qwen_Qwen2.5-0.5B_latent8_lr0.0005_quant16_batch64_runs5/benchmark_config.json (deflated 58%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-0.5B/benchmark_Qwen_Qwen2.5-0.5B_latent8_lr0.0005_quant4_batch64_runs5/ (stored 0%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-0.5B/benchmark_Qwen_Qwen2.5-0.5B_latent8_lr0.0005_quant4_batch64_runs5/benchmark_results.json (deflated 69%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-0.5B/benchmark_Qwen_Qwen2.5-0.5B_latent8_lr0.0005_quant4_batch64_runs5/benchmark_config.json (deflated 58%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-0.5B/benchmark_Qwen_Qwen2.5-0.5B_latent8_lr0.0005_quant2_batch64_runs5/ (stored 0%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-0.5B/benchmark_Qwen_Qwen2.5-0.5B_latent8_lr0.0005_quant2_batch64_runs5/benchmark_results.json (deflated 68%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-0.5B/benchmark_Qwen_Qwen2.5-0.5B_latent8_lr0.0005_quant2_batch64_runs5/benchmark_config.json (deflated 59%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-0.5B/Qwen_Qwen2.5-0.5B_latent8_lr0.001/ (stored 0%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-0.5B/Qwen_Qwen2.5-0.5B_latent8_lr0.001/attention_viz/ (stored 0%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-0.5B/Qwen_Qwen2.5-0.5B_latent8_lr0.001/attention_viz/epoch_1_batch_100_layer_0_head_0.png (deflated 1%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-0.5B/Qwen_Qwen2.5-0.5B_latent8_lr0.001/attention_viz/epoch_1_batch_200_layer_0_head_0.png (deflated 1%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-0.5B/Qwen_Qwen2.5-0.5B_latent8_lr0.001/attention_viz/epoch_1_batch_0_layer_0_head_0.png (deflated 19%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-0.5B/Qwen_Qwen2.5-0.5B_latent8_lr0.001/train_config.json (deflated 52%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-0.5B/benchmark_Qwen_Qwen2.5-0.5B_latent8_lr0.0005_quant8_batch64_runs5/ (stored 0%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-0.5B/benchmark_Qwen_Qwen2.5-0.5B_latent8_lr0.0005_quant8_batch64_runs5/benchmark_results.json (deflated 68%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-0.5B/benchmark_Qwen_Qwen2.5-0.5B_latent8_lr0.0005_quant8_batch64_runs5/benchmark_config.json (deflated 58%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-3B/ (stored 0%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-3B/Qwen_Qwen2.5-3B_latent16_lr0.0005/ (stored 0%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-3B/Qwen_Qwen2.5-3B_latent16_lr0.0005/train_config.json (deflated 53%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-3B/Qwen_Qwen2.5-3B_latent8_lr0.0001/ (stored 0%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-3B/Qwen_Qwen2.5-3B_latent8_lr0.0001/train_config.json (deflated 53%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-3B/Qwen_Qwen2.5-3B_latent8_lr0.001/ (stored 0%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-3B/Qwen_Qwen2.5-3B_latent8_lr0.001/attention_viz/ (stored 0%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-3B/Qwen_Qwen2.5-3B_latent8_lr0.001/attention_viz/epoch_1_batch_0_layer_0_head_0.png (deflated 17%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-3B/Qwen_Qwen2.5-3B_latent8_lr0.001/train_config.json (deflated 52%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-3B/Qwen_Qwen2.5-3B_latent16_lr0.001/ (stored 0%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-3B/Qwen_Qwen2.5-3B_latent16_lr0.001/train_config.json (deflated 53%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-3B/benchmark_Qwen_Qwen2.5-3B_latent16_lr0.0001_batch64_runs5/ (stored 0%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-3B/benchmark_Qwen_Qwen2.5-3B_latent16_lr0.0001_batch64_runs5/benchmark_config.json (deflated 58%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-3B/Qwen_Qwen2.5-3B_latent32_lr0.001/ (stored 0%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-3B/Qwen_Qwen2.5-3B_latent32_lr0.001/train_config.json (deflated 52%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-3B/benchmark_Qwen_Qwen2.5-3B_latent16_lr0.0005_batch64_runs5/ (stored 0%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-3B/benchmark_Qwen_Qwen2.5-3B_latent16_lr0.0005_batch64_runs5/benchmark_config.json (deflated 58%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-3B/benchmark_Qwen_Qwen2.5-3B_latent16_lr0.001_batch64_runs5/ (stored 0%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-3B/benchmark_Qwen_Qwen2.5-3B_latent16_lr0.001_batch64_runs5/benchmark_config.json (deflated 58%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-3B/benchmark_Qwen_Qwen2.5-3B_latent32_lr0.0001_batch64_runs5/ (stored 0%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-3B/benchmark_Qwen_Qwen2.5-3B_latent32_lr0.0001_batch64_runs5/benchmark_config.json (deflated 58%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-3B/Qwen_Qwen2.5-3B_latent32_lr0.0001/ (stored 0%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-3B/Qwen_Qwen2.5-3B_latent32_lr0.0001/train_config.json (deflated 53%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-3B/Qwen_Qwen2.5-3B_latent16_lr0.0001/ (stored 0%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-3B/Qwen_Qwen2.5-3B_latent16_lr0.0001/train_config.json (deflated 53%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-3B/Qwen_Qwen2.5-3B_latent8_lr0.0005/ (stored 0%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-3B/Qwen_Qwen2.5-3B_latent8_lr0.0005/train_config.json (deflated 53%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-3B/Qwen_Qwen2.5-3B_latent32_lr0.0005/ (stored 0%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-3B/Qwen_Qwen2.5-3B_latent32_lr0.0005/train_config.json (deflated 53%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-3B/benchmark_Qwen_Qwen2.5-3B_latent8_lr0.0005_batch64_runs5/ (stored 0%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-3B/benchmark_Qwen_Qwen2.5-3B_latent8_lr0.0005_batch64_runs5/benchmark_config.json (deflated 58%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-3B/benchmark_Qwen_Qwen2.5-3B_latent8_lr0.001_batch64_runs5/ (stored 0%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-3B/benchmark_Qwen_Qwen2.5-3B_latent8_lr0.001_batch64_runs5/benchmark_config.json (deflated 57%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-3B/benchmark_Qwen_Qwen2.5-3B_latent8_lr0.0001_batch64_runs5/ (stored 0%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-3B/benchmark_Qwen_Qwen2.5-3B_latent8_lr0.0001_batch64_runs5/benchmark_config.json (deflated 58%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-3B/benchmark_Qwen_Qwen2.5-3B_latent32_lr0.0005_batch64_runs5/ (stored 0%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-3B/benchmark_Qwen_Qwen2.5-3B_latent32_lr0.0005_batch64_runs5/benchmark_config.json (deflated 58%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-3B/benchmark_Qwen_Qwen2.5-3B_latent32_lr0.001_batch64_runs5/ (stored 0%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-3B/benchmark_Qwen_Qwen2.5-3B_latent32_lr0.001_batch64_runs5/benchmark_config.json (deflated 58%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-7B/ (stored 0%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-7B/Qwen_Qwen2.5-7B_latent8/ (stored 0%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-7B/Qwen_Qwen2.5-7B_latent8/attention_viz/ (stored 0%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-7B/Qwen_Qwen2.5-7B_latent8/attention_viz/epoch_1_batch_300_layer_0_head_0.png (deflated 1%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-7B/Qwen_Qwen2.5-7B_latent8/attention_viz/epoch_1_batch_100_layer_0_head_0.png (deflated 1%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-7B/Qwen_Qwen2.5-7B_latent8/attention_viz/epoch_1_batch_200_layer_0_head_0.png (deflated 1%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-7B/Qwen_Qwen2.5-7B_latent8/attention_viz/epoch_1_batch_0_layer_0_head_0.png (deflated 4%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-7B/Qwen_Qwen2.5-7B_latent8/train_config.json (deflated 52%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-7B/benchmark_Qwen_Qwen2.5-7B_latent8_lr0.001_batch64_runs5/ (stored 0%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-7B/benchmark_Qwen_Qwen2.5-7B_latent8_lr0.001_batch64_runs5/benchmark_config.json (deflated 57%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-7B/Qwen_Qwen2.5-7B_latent8_lr0.001/ (stored 0%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-7B/Qwen_Qwen2.5-7B_latent8_lr0.001/attention_viz/ (stored 0%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-7B/Qwen_Qwen2.5-7B_latent8_lr0.001/attention_viz/epoch_1_batch_800_layer_0_head_0.png (deflated 1%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-7B/Qwen_Qwen2.5-7B_latent8_lr0.001/attention_viz/epoch_1_batch_300_layer_0_head_0.png (deflated 1%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-7B/Qwen_Qwen2.5-7B_latent8_lr0.001/attention_viz/epoch_1_batch_100_layer_0_head_0.png (deflated 1%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-7B/Qwen_Qwen2.5-7B_latent8_lr0.001/attention_viz/epoch_2_batch_0_layer_0_head_0.png (deflated 1%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-7B/Qwen_Qwen2.5-7B_latent8_lr0.001/attention_viz/epoch_1_batch_400_layer_0_head_0.png (deflated 1%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-7B/Qwen_Qwen2.5-7B_latent8_lr0.001/attention_viz/epoch_1_batch_200_layer_0_head_0.png (deflated 1%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-7B/Qwen_Qwen2.5-7B_latent8_lr0.001/attention_viz/epoch_1_batch_900_layer_0_head_0.png (deflated 1%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-7B/Qwen_Qwen2.5-7B_latent8_lr0.001/attention_viz/epoch_1_batch_700_layer_0_head_0.png (deflated 1%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-7B/Qwen_Qwen2.5-7B_latent8_lr0.001/attention_viz/epoch_1_batch_500_layer_0_head_0.png (deflated 1%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-7B/Qwen_Qwen2.5-7B_latent8_lr0.001/attention_viz/epoch_1_batch_600_layer_0_head_0.png (deflated 1%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-7B/Qwen_Qwen2.5-7B_latent8_lr0.001/attention_viz/epoch_1_batch_0_layer_0_head_0.png (deflated 19%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-7B/Qwen_Qwen2.5-7B_latent8_lr0.001/train_config.json (deflated 52%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-7B/Qwen_Qwen2.5-7B_latent8_lr0.0005/ (stored 0%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-7B/Qwen_Qwen2.5-7B_latent8_lr0.0005/train_config.json (deflated 52%)\n",
            "updating: experiment_results_Qwen/experiment_summary.json (deflated 83%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-0.5B/benchmark_Qwen_Qwen2.5-0.5B_latent16_lr0.0005_quant8_batch64_runs5/ (stored 0%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-0.5B/benchmark_Qwen_Qwen2.5-0.5B_latent16_lr0.0005_quant8_batch64_runs5/benchmark_results.json (deflated 68%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-0.5B/benchmark_Qwen_Qwen2.5-0.5B_latent16_lr0.0005_quant8_batch64_runs5/benchmark_config.json (deflated 58%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-0.5B/benchmark_Qwen_Qwen2.5-0.5B_latent16_lr0.0005_quant16_batch64_runs5/ (stored 0%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-0.5B/benchmark_Qwen_Qwen2.5-0.5B_latent16_lr0.0005_quant16_batch64_runs5/benchmark_results.json (deflated 68%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-0.5B/benchmark_Qwen_Qwen2.5-0.5B_latent16_lr0.0005_quant16_batch64_runs5/benchmark_config.json (deflated 58%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-0.5B/Qwen_Qwen2.5-0.5B_latent16_lr0.0005_epochs5_texts10000/ (stored 0%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-0.5B/Qwen_Qwen2.5-0.5B_latent16_lr0.0005/ (stored 0%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-0.5B/Qwen_Qwen2.5-0.5B_latent16_lr0.0005/attention_viz/ (stored 0%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-0.5B/Qwen_Qwen2.5-0.5B_latent16_lr0.0005/autoencoders_final.pth (deflated 37%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-0.5B/Qwen_Qwen2.5-0.5B_latent16_lr0.0005/train_config.json (deflated 52%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-0.5B/Qwen_Qwen2.5-0.5B_latent16_lr0.0005/autoencoders_epoch_5.pth (deflated 37%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-0.5B/benchmark_Qwen_Qwen2.5-0.5B_latent16_lr0.0005_quant2_batch64_runs5/ (stored 0%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-0.5B/benchmark_Qwen_Qwen2.5-0.5B_latent16_lr0.0005_quant2_batch64_runs5/benchmark_results.json (deflated 69%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-0.5B/benchmark_Qwen_Qwen2.5-0.5B_latent16_lr0.0005_quant2_batch64_runs5/benchmark_config.json (deflated 58%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-0.5B/benchmark_Qwen_Qwen2.5-0.5B_latent16_lr0.0005_quant4_batch64_runs5/ (stored 0%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-0.5B/benchmark_Qwen_Qwen2.5-0.5B_latent16_lr0.0005_quant4_batch64_runs5/benchmark_results.json (deflated 68%)\n",
            "updating: experiment_results_Qwen/Qwen_Qwen2.5-0.5B/benchmark_Qwen_Qwen2.5-0.5B_latent16_lr0.0005_quant4_batch64_runs5/benchmark_config.json (deflated 58%)\n",
            "  adding: experiment_results_Qwen/Qwen_Qwen2.5-0.5B/benchmark_Qwen_Qwen2.5-0.5B_latent32_lr0.0005_quant16_batch64_runs5/ (stored 0%)\n",
            "  adding: experiment_results_Qwen/Qwen_Qwen2.5-0.5B/benchmark_Qwen_Qwen2.5-0.5B_latent32_lr0.0005_quant16_batch64_runs5/benchmark_results.json (deflated 68%)\n",
            "  adding: experiment_results_Qwen/Qwen_Qwen2.5-0.5B/benchmark_Qwen_Qwen2.5-0.5B_latent32_lr0.0005_quant16_batch64_runs5/benchmark_config.json (deflated 58%)\n",
            "  adding: experiment_results_Qwen/Qwen_Qwen2.5-0.5B/benchmark_Qwen_Qwen2.5-0.5B_latent32_lr0.0005_quant8_batch64_runs5/ (stored 0%)\n",
            "  adding: experiment_results_Qwen/Qwen_Qwen2.5-0.5B/benchmark_Qwen_Qwen2.5-0.5B_latent32_lr0.0005_quant8_batch64_runs5/benchmark_results.json (deflated 68%)\n",
            "  adding: experiment_results_Qwen/Qwen_Qwen2.5-0.5B/benchmark_Qwen_Qwen2.5-0.5B_latent32_lr0.0005_quant8_batch64_runs5/benchmark_config.json (deflated 58%)\n",
            "  adding: experiment_results_Qwen/Qwen_Qwen2.5-0.5B/benchmark_Qwen_Qwen2.5-0.5B_latent32_lr0.0005_quant2_batch64_runs5/ (stored 0%)\n",
            "  adding: experiment_results_Qwen/Qwen_Qwen2.5-0.5B/benchmark_Qwen_Qwen2.5-0.5B_latent32_lr0.0005_quant2_batch64_runs5/benchmark_results.json (deflated 68%)\n",
            "  adding: experiment_results_Qwen/Qwen_Qwen2.5-0.5B/benchmark_Qwen_Qwen2.5-0.5B_latent32_lr0.0005_quant2_batch64_runs5/benchmark_config.json (deflated 58%)\n",
            "  adding: experiment_results_Qwen/Qwen_Qwen2.5-0.5B/benchmark_Qwen_Qwen2.5-0.5B_latent32_lr0.0005_quant4_batch64_runs5/ (stored 0%)\n",
            "  adding: experiment_results_Qwen/Qwen_Qwen2.5-0.5B/benchmark_Qwen_Qwen2.5-0.5B_latent32_lr0.0005_quant4_batch64_runs5/benchmark_results.json (deflated 68%)\n",
            "  adding: experiment_results_Qwen/Qwen_Qwen2.5-0.5B/benchmark_Qwen_Qwen2.5-0.5B_latent32_lr0.0005_quant4_batch64_runs5/benchmark_config.json (deflated 58%)\n",
            "  adding: experiment_results_Qwen/Qwen_Qwen2.5-0.5B/Qwen_Qwen2.5-0.5B_latent32_lr0.0005_epochs5_texts10000/ (stored 0%)\n",
            "  adding: experiment_results_Qwen/Qwen_Qwen2.5-0.5B/Qwen_Qwen2.5-0.5B_latent32_lr0.0005/ (stored 0%)\n",
            "  adding: experiment_results_Qwen/Qwen_Qwen2.5-0.5B/Qwen_Qwen2.5-0.5B_latent32_lr0.0005/attention_viz/ (stored 0%)\n",
            "  adding: experiment_results_Qwen/Qwen_Qwen2.5-0.5B/Qwen_Qwen2.5-0.5B_latent32_lr0.0005/autoencoders_final.pth (deflated 32%)\n",
            "  adding: experiment_results_Qwen/Qwen_Qwen2.5-0.5B/Qwen_Qwen2.5-0.5B_latent32_lr0.0005/train_config.json (deflated 52%)\n",
            "  adding: experiment_results_Qwen/Qwen_Qwen2.5-0.5B/Qwen_Qwen2.5-0.5B_latent32_lr0.0005/autoencoders_epoch_5.pth (deflated 32%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_68d46370-e43f-4ac9-9021-ef972a29905f\", \"experiment_results_Qwen.zip\", 10196581)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}