2025-04-02 22:06:35,371 [INFO] 
================================================================================
2025-04-02 22:06:35,372 [INFO] Starting KV Cache Compression Experiments
2025-04-02 22:06:35,373 [INFO] ================================================================================
2025-04-02 22:06:35,373 [INFO] Model: distilgpt2
2025-04-02 22:06:35,373 [INFO] Latent dimensions: [8, 16, 32]
2025-04-02 22:06:35,373 [INFO] KV cache sizes (MB): [1.0, 10.0, 100.0, 1000.0, 3000.0]
2025-04-02 22:06:35,373 [INFO] Number of epochs: 5
2025-04-02 22:06:35,373 [INFO] Number of training texts: 1000
2025-04-02 22:06:35,373 [INFO] Batch size: 1024
2025-04-02 22:06:35,373 [INFO] Number of runs for timing: 5
2025-04-02 22:06:35,373 [INFO] Maximum token chunk size: 128
2025-04-02 22:06:35,373 [INFO] Output directory: experiment_results_distilgpt2
2025-04-02 22:06:35,373 [INFO] 
================================================================================
2025-04-02 22:06:35,373 [INFO] Processing latent_dim=8
2025-04-02 22:06:35,373 [INFO] ================================================================================
2025-04-02 22:09:01,436 [INFO] 
================================================================================
2025-04-02 22:09:01,437 [INFO] Starting KV Cache Compression Experiments
2025-04-02 22:09:01,437 [INFO] ================================================================================
2025-04-02 22:09:01,437 [INFO] Model: distilgpt2
2025-04-02 22:09:01,437 [INFO] Latent dimensions: [8, 16, 32]
2025-04-02 22:09:01,437 [INFO] KV cache sizes (MB): [1.0, 10.0, 100.0, 1000.0, 3000.0]
2025-04-02 22:09:01,437 [INFO] Number of epochs: 5
2025-04-02 22:09:01,437 [INFO] Number of training texts: 1000
2025-04-02 22:09:01,437 [INFO] Batch size: 1024
2025-04-02 22:09:01,437 [INFO] Number of runs for timing: 5
2025-04-02 22:09:01,437 [INFO] Maximum token chunk size: 128
2025-04-02 22:09:01,437 [INFO] Output directory: experiment_results_distilgpt2
2025-04-02 22:09:01,437 [INFO] 
================================================================================
2025-04-02 22:09:01,437 [INFO] Processing latent_dim=8
2025-04-02 22:09:01,437 [INFO] ================================================================================
2025-04-02 22:09:03,363 [INFO] CUDA cache cleared
2025-04-02 22:09:03,393 [INFO] Garbage collector run
2025-04-02 22:09:03,394 [INFO] 
================================================================================
2025-04-02 22:09:03,394 [INFO] Training autoencoder with latent_dim=8
2025-04-02 22:09:03,394 [INFO] ================================================================================
2025-04-02 22:09:03,394 [INFO] Running: python -m src.dictionary_learning.train --name distilgpt2 --latent_dim 8 --num_epochs 5 --num_train_texts 1000 --output_dir experiment_results_distilgpt2/distilgpt2_latent8
2025-04-02 22:09:35,157 [INFO] Command completed successfully
2025-04-02 22:09:35,158 [INFO] Autoencoder trained and saved to experiment_results_distilgpt2/distilgpt2_latent8/autoencoder_final.pth
2025-04-02 22:09:35,158 [INFO] CUDA cache cleared
2025-04-02 22:09:35,188 [INFO] Garbage collector run
2025-04-02 22:09:35,189 [INFO] 
================================================================================
2025-04-02 22:09:35,189 [INFO] Running benchmark with latent_dim=8
2025-04-02 22:09:35,189 [INFO] ================================================================================
2025-04-02 22:09:35,189 [INFO] Running: python -m src.inference.benchmark --model distilgpt2 --autoencoder experiment_results_distilgpt2/distilgpt2_latent8/autoencoder_final.pth --latent_dim 8 --batch_size 1024 --num_runs 5 --max_token_chunk 128 --sizes 1.0 10.0 100.0 1000.0 3000.0 --output experiment_results_distilgpt2/benchmark_distilgpt2_latent8
2025-04-02 22:09:39,798 [ERROR] Command failed with exit code 1
2025-04-02 22:09:39,798 [ERROR] STDOUT: 
2025-04-02 22:09:39,798 [ERROR] STDERR: Traceback (most recent call last):
  File "/n/sw/Mambaforge-23.11.0-0/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/n/sw/Mambaforge-23.11.0-0/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/n/holylabs/LABS/meng_lab/Lab/learned-kv-compression/src/inference/benchmark.py", line 21, in <module>
    from src.inference.inference import compress_kv_cache, decompress_kv_cache, generate_kv_cache
ImportError: cannot import name 'compress_kv_cache' from 'src.inference.inference' (/n/holylabs/LABS/meng_lab/Lab/learned-kv-compression/src/inference/inference.py)

2025-04-02 22:09:39,798 [ERROR] Failed to run benchmark with latent_dim=8
2025-04-02 22:09:41,800 [INFO] 
================================================================================
2025-04-02 22:09:41,801 [INFO] Processing latent_dim=16
2025-04-02 22:09:41,801 [INFO] ================================================================================
2025-04-02 22:09:41,801 [INFO] CUDA cache cleared
2025-04-02 22:09:41,835 [INFO] Garbage collector run
2025-04-02 22:09:41,835 [INFO] 
================================================================================
2025-04-02 22:09:41,835 [INFO] Training autoencoder with latent_dim=16
2025-04-02 22:09:41,835 [INFO] ================================================================================
2025-04-02 22:09:41,835 [INFO] Running: python -m src.dictionary_learning.train --name distilgpt2 --latent_dim 16 --num_epochs 5 --num_train_texts 1000 --output_dir experiment_results_distilgpt2/distilgpt2_latent16
2025-04-02 22:10:02,986 [INFO] Command completed successfully
2025-04-02 22:10:02,986 [INFO] Autoencoder trained and saved to experiment_results_distilgpt2/distilgpt2_latent16/autoencoder_final.pth
2025-04-02 22:10:02,987 [INFO] CUDA cache cleared
2025-04-02 22:10:03,012 [INFO] Garbage collector run
2025-04-02 22:10:03,012 [INFO] 
================================================================================
2025-04-02 22:10:03,012 [INFO] Running benchmark with latent_dim=16
2025-04-02 22:10:03,012 [INFO] ================================================================================
2025-04-02 22:10:03,012 [INFO] Running: python -m src.inference.benchmark --model distilgpt2 --autoencoder experiment_results_distilgpt2/distilgpt2_latent16/autoencoder_final.pth --latent_dim 16 --batch_size 1024 --num_runs 5 --max_token_chunk 128 --sizes 1.0 10.0 100.0 1000.0 3000.0 --output experiment_results_distilgpt2/benchmark_distilgpt2_latent16
2025-04-02 22:10:07,573 [ERROR] Command failed with exit code 1
2025-04-02 22:10:07,573 [ERROR] STDOUT: 
2025-04-02 22:10:07,573 [ERROR] STDERR: Traceback (most recent call last):
  File "/n/sw/Mambaforge-23.11.0-0/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/n/sw/Mambaforge-23.11.0-0/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/n/holylabs/LABS/meng_lab/Lab/learned-kv-compression/src/inference/benchmark.py", line 21, in <module>
    from src.inference.inference import compress_kv_cache, decompress_kv_cache, generate_kv_cache
ImportError: cannot import name 'compress_kv_cache' from 'src.inference.inference' (/n/holylabs/LABS/meng_lab/Lab/learned-kv-compression/src/inference/inference.py)

2025-04-02 22:10:07,573 [ERROR] Failed to run benchmark with latent_dim=16
2025-04-02 22:10:09,575 [INFO] 
================================================================================
2025-04-02 22:10:09,575 [INFO] Processing latent_dim=32
2025-04-02 22:10:09,575 [INFO] ================================================================================
2025-04-02 22:10:09,576 [INFO] CUDA cache cleared
2025-04-02 22:10:09,601 [INFO] Garbage collector run
2025-04-02 22:10:09,601 [INFO] 
================================================================================
2025-04-02 22:10:09,601 [INFO] Training autoencoder with latent_dim=32
2025-04-02 22:10:09,601 [INFO] ================================================================================
2025-04-02 22:10:09,601 [INFO] Running: python -m src.dictionary_learning.train --name distilgpt2 --latent_dim 32 --num_epochs 5 --num_train_texts 1000 --output_dir experiment_results_distilgpt2/distilgpt2_latent32
2025-04-02 22:10:31,765 [INFO] Command completed successfully
2025-04-02 22:10:31,766 [INFO] Autoencoder trained and saved to experiment_results_distilgpt2/distilgpt2_latent32/autoencoder_final.pth
2025-04-02 22:10:31,766 [INFO] CUDA cache cleared
2025-04-02 22:10:31,797 [INFO] Garbage collector run
2025-04-02 22:10:31,797 [INFO] 
================================================================================
2025-04-02 22:10:31,797 [INFO] Running benchmark with latent_dim=32
2025-04-02 22:10:31,797 [INFO] ================================================================================
2025-04-02 22:10:31,797 [INFO] Running: python -m src.inference.benchmark --model distilgpt2 --autoencoder experiment_results_distilgpt2/distilgpt2_latent32/autoencoder_final.pth --latent_dim 32 --batch_size 1024 --num_runs 5 --max_token_chunk 128 --sizes 1.0 10.0 100.0 1000.0 3000.0 --output experiment_results_distilgpt2/benchmark_distilgpt2_latent32
2025-04-02 22:10:36,336 [ERROR] Command failed with exit code 1
2025-04-02 22:10:36,336 [ERROR] STDOUT: 
2025-04-02 22:10:36,336 [ERROR] STDERR: Traceback (most recent call last):
  File "/n/sw/Mambaforge-23.11.0-0/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/n/sw/Mambaforge-23.11.0-0/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/n/holylabs/LABS/meng_lab/Lab/learned-kv-compression/src/inference/benchmark.py", line 21, in <module>
    from src.inference.inference import compress_kv_cache, decompress_kv_cache, generate_kv_cache
ImportError: cannot import name 'compress_kv_cache' from 'src.inference.inference' (/n/holylabs/LABS/meng_lab/Lab/learned-kv-compression/src/inference/inference.py)

2025-04-02 22:10:36,336 [ERROR] Failed to run benchmark with latent_dim=32
2025-04-02 22:10:38,338 [INFO] 
================================================================================
2025-04-02 22:10:38,338 [INFO] Experiment Summary
2025-04-02 22:10:38,338 [INFO] ================================================================================
2025-04-02 22:10:38,338 [INFO] Model: distilgpt2
2025-04-02 22:10:38,338 [INFO] Latent dimensions tested: [8, 16, 32]
2025-04-02 22:10:38,338 [INFO] KV cache sizes tested: [1.0, 10.0, 100.0, 1000.0, 3000.0] MB
2025-04-02 22:10:38,338 [INFO] Batch size: 1024
2025-04-02 22:10:38,338 [INFO] Number of runs for timing: 5
2025-04-02 22:10:38,338 [INFO] Total runtime: 0h 1m 36.90s
2025-04-02 22:10:38,338 [INFO] Results saved to: experiment_results_distilgpt2
2025-04-02 22:10:38,339 [WARNING] No successful results were produced
2025-04-02 22:10:38,339 [WARNING] Failed dimensions:
2025-04-02 22:10:38,339 [WARNING] - Latent dim 8: benchmark failed
2025-04-02 22:10:38,339 [WARNING] - Latent dim 16: benchmark failed
2025-04-02 22:10:38,339 [WARNING] - Latent dim 32: benchmark failed
2025-04-02 22:10:38,339 [INFO] ================================================================================
2025-04-02 22:10:38,341 [INFO] Summary saved to experiment_results_distilgpt2/experiment_summary.txt
2025-04-02 22:11:37,443 [INFO] 
================================================================================
2025-04-02 22:11:37,443 [INFO] Starting KV Cache Compression Experiments
2025-04-02 22:11:37,443 [INFO] ================================================================================
2025-04-02 22:11:37,443 [INFO] Model: distilgpt2
2025-04-02 22:11:37,444 [INFO] Latent dimensions: [8, 16, 32]
2025-04-02 22:11:37,444 [INFO] KV cache sizes (MB): [1.0, 10.0, 100.0, 1000.0, 3000.0]
2025-04-02 22:11:37,444 [INFO] Number of epochs: 5
2025-04-02 22:11:37,444 [INFO] Number of training texts: 1000
2025-04-02 22:11:37,444 [INFO] Batch size: 1024
2025-04-02 22:11:37,444 [INFO] Number of runs for timing: 5
2025-04-02 22:11:37,444 [INFO] Maximum token chunk size: 128
2025-04-02 22:11:37,444 [INFO] Output directory: experiment_results_distilgpt2
2025-04-02 22:11:37,444 [INFO] 
================================================================================
2025-04-02 22:11:37,444 [INFO] Processing latent_dim=8
2025-04-02 22:11:37,444 [INFO] ================================================================================
2025-04-02 22:11:38,944 [INFO] CUDA cache cleared
2025-04-02 22:11:38,974 [INFO] Garbage collector run
2025-04-02 22:11:38,974 [INFO] 
================================================================================
2025-04-02 22:11:38,974 [INFO] Training autoencoder with latent_dim=8
2025-04-02 22:11:38,974 [INFO] ================================================================================
2025-04-02 22:11:38,974 [INFO] Running: python -m src.dictionary_learning.train --name distilgpt2 --latent_dim 8 --num_epochs 5 --num_train_texts 1000 --output_dir experiment_results_distilgpt2/distilgpt2_latent8
2025-04-02 22:11:59,844 [INFO] Command completed successfully
2025-04-02 22:11:59,845 [INFO] Autoencoder trained and saved to experiment_results_distilgpt2/distilgpt2_latent8/autoencoder_final.pth
2025-04-02 22:11:59,846 [INFO] CUDA cache cleared
2025-04-02 22:11:59,876 [INFO] Garbage collector run
2025-04-02 22:11:59,876 [INFO] 
================================================================================
2025-04-02 22:11:59,876 [INFO] Running benchmark with latent_dim=8
2025-04-02 22:11:59,876 [INFO] ================================================================================
2025-04-02 22:11:59,876 [INFO] Running: python -m src.inference.benchmark --model distilgpt2 --autoencoder experiment_results_distilgpt2/distilgpt2_latent8/autoencoder_final.pth --latent_dim 8 --batch_size 1024 --num_runs 5 --max_token_chunk 128 --sizes 1.0 10.0 100.0 1000.0 3000.0 --output experiment_results_distilgpt2/benchmark_distilgpt2_latent8
2025-04-02 22:12:04,435 [ERROR] Command failed with exit code 1
2025-04-02 22:12:04,435 [ERROR] STDOUT: 
2025-04-02 22:12:04,435 [ERROR] STDERR: Traceback (most recent call last):
  File "/n/sw/Mambaforge-23.11.0-0/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/n/sw/Mambaforge-23.11.0-0/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/n/holylabs/LABS/meng_lab/Lab/learned-kv-compression/src/inference/benchmark.py", line 21, in <module>
    from src.inference.inference import compress_kv_cache, decompress_kv_cache, generate_kv_cache
ImportError: cannot import name 'compress_kv_cache' from 'src.inference.inference' (/n/holylabs/LABS/meng_lab/Lab/learned-kv-compression/src/inference/inference.py)

2025-04-02 22:12:04,435 [ERROR] Failed to run benchmark with latent_dim=8
2025-04-02 22:12:06,438 [INFO] 
================================================================================
2025-04-02 22:12:06,438 [INFO] Processing latent_dim=16
2025-04-02 22:12:06,438 [INFO] ================================================================================
2025-04-02 22:12:06,438 [INFO] CUDA cache cleared
2025-04-02 22:12:06,470 [INFO] Garbage collector run
2025-04-02 22:12:06,470 [INFO] 
================================================================================
2025-04-02 22:12:06,470 [INFO] Training autoencoder with latent_dim=16
2025-04-02 22:12:06,470 [INFO] ================================================================================
2025-04-02 22:12:06,470 [INFO] Running: python -m src.dictionary_learning.train --name distilgpt2 --latent_dim 16 --num_epochs 5 --num_train_texts 1000 --output_dir experiment_results_distilgpt2/distilgpt2_latent16
2025-04-02 22:12:27,280 [INFO] Command completed successfully
2025-04-02 22:12:27,282 [INFO] Autoencoder trained and saved to experiment_results_distilgpt2/distilgpt2_latent16/autoencoder_final.pth
2025-04-02 22:12:27,282 [INFO] CUDA cache cleared
2025-04-02 22:12:27,307 [INFO] Garbage collector run
2025-04-02 22:12:27,307 [INFO] 
================================================================================
2025-04-02 22:12:27,308 [INFO] Running benchmark with latent_dim=16
2025-04-02 22:12:27,308 [INFO] ================================================================================
2025-04-02 22:12:27,308 [INFO] Running: python -m src.inference.benchmark --model distilgpt2 --autoencoder experiment_results_distilgpt2/distilgpt2_latent16/autoencoder_final.pth --latent_dim 16 --batch_size 1024 --num_runs 5 --max_token_chunk 128 --sizes 1.0 10.0 100.0 1000.0 3000.0 --output experiment_results_distilgpt2/benchmark_distilgpt2_latent16
2025-04-02 22:12:31,848 [ERROR] Command failed with exit code 1
2025-04-02 22:12:31,848 [ERROR] STDOUT: 
2025-04-02 22:12:31,848 [ERROR] STDERR: Traceback (most recent call last):
  File "/n/sw/Mambaforge-23.11.0-0/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/n/sw/Mambaforge-23.11.0-0/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/n/holylabs/LABS/meng_lab/Lab/learned-kv-compression/src/inference/benchmark.py", line 21, in <module>
    from src.inference.inference import compress_kv_cache, decompress_kv_cache, generate_kv_cache
ImportError: cannot import name 'compress_kv_cache' from 'src.inference.inference' (/n/holylabs/LABS/meng_lab/Lab/learned-kv-compression/src/inference/inference.py)

2025-04-02 22:12:31,848 [ERROR] Failed to run benchmark with latent_dim=16
2025-04-02 22:12:33,850 [INFO] 
================================================================================
2025-04-02 22:12:33,850 [INFO] Processing latent_dim=32
2025-04-02 22:12:33,850 [INFO] ================================================================================
2025-04-02 22:12:33,850 [INFO] CUDA cache cleared
2025-04-02 22:12:33,882 [INFO] Garbage collector run
2025-04-02 22:12:33,882 [INFO] 
================================================================================
2025-04-02 22:12:33,882 [INFO] Training autoencoder with latent_dim=32
2025-04-02 22:12:33,882 [INFO] ================================================================================
2025-04-02 22:12:33,882 [INFO] Running: python -m src.dictionary_learning.train --name distilgpt2 --latent_dim 32 --num_epochs 5 --num_train_texts 1000 --output_dir experiment_results_distilgpt2/distilgpt2_latent32
2025-04-02 22:12:57,093 [INFO] Command completed successfully
2025-04-02 22:12:57,095 [INFO] Autoencoder trained and saved to experiment_results_distilgpt2/distilgpt2_latent32/autoencoder_final.pth
2025-04-02 22:12:57,095 [INFO] CUDA cache cleared
2025-04-02 22:12:57,120 [INFO] Garbage collector run
2025-04-02 22:12:57,121 [INFO] 
================================================================================
2025-04-02 22:12:57,121 [INFO] Running benchmark with latent_dim=32
2025-04-02 22:12:57,121 [INFO] ================================================================================
2025-04-02 22:12:57,121 [INFO] Running: python -m src.inference.benchmark --model distilgpt2 --autoencoder experiment_results_distilgpt2/distilgpt2_latent32/autoencoder_final.pth --latent_dim 32 --batch_size 1024 --num_runs 5 --max_token_chunk 128 --sizes 1.0 10.0 100.0 1000.0 3000.0 --output experiment_results_distilgpt2/benchmark_distilgpt2_latent32
2025-04-02 22:13:01,688 [ERROR] Command failed with exit code 1
2025-04-02 22:13:01,688 [ERROR] STDOUT: 
2025-04-02 22:13:01,688 [ERROR] STDERR: Traceback (most recent call last):
  File "/n/sw/Mambaforge-23.11.0-0/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/n/sw/Mambaforge-23.11.0-0/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/n/holylabs/LABS/meng_lab/Lab/learned-kv-compression/src/inference/benchmark.py", line 21, in <module>
    from src.inference.inference import compress_kv_cache, decompress_kv_cache, generate_kv_cache
ImportError: cannot import name 'compress_kv_cache' from 'src.inference.inference' (/n/holylabs/LABS/meng_lab/Lab/learned-kv-compression/src/inference/inference.py)

2025-04-02 22:13:01,688 [ERROR] Failed to run benchmark with latent_dim=32
2025-04-02 22:13:03,690 [INFO] 
================================================================================
2025-04-02 22:13:03,691 [INFO] Experiment Summary
2025-04-02 22:13:03,691 [INFO] ================================================================================
2025-04-02 22:13:03,691 [INFO] Model: distilgpt2
2025-04-02 22:13:03,691 [INFO] Latent dimensions tested: [8, 16, 32]
2025-04-02 22:13:03,691 [INFO] KV cache sizes tested: [1.0, 10.0, 100.0, 1000.0, 3000.0] MB
2025-04-02 22:13:03,691 [INFO] Batch size: 1024
2025-04-02 22:13:03,691 [INFO] Number of runs for timing: 5
2025-04-02 22:13:03,691 [INFO] Total runtime: 0h 1m 26.25s
2025-04-02 22:13:03,691 [INFO] Results saved to: experiment_results_distilgpt2
2025-04-02 22:13:03,691 [WARNING] No successful results were produced
2025-04-02 22:13:03,691 [WARNING] Failed dimensions:
2025-04-02 22:13:03,691 [WARNING] - Latent dim 8: benchmark failed
2025-04-02 22:13:03,691 [WARNING] - Latent dim 16: benchmark failed
2025-04-02 22:13:03,691 [WARNING] - Latent dim 32: benchmark failed
2025-04-02 22:13:03,691 [INFO] ================================================================================
2025-04-02 22:13:03,692 [INFO] Summary saved to experiment_results_distilgpt2/experiment_summary.txt
