{
    "model_name": "Qwen/Qwen2.5-0.5B",
    "autoencoder_path": "experiment_results_Qwen/Qwen_Qwen2.5-0.5B/Qwen_Qwen2.5-0.5B_latent32_lr0.0005/autoencoders_final.pth",
    "latent_dim": 32,
    "seed": 42,
    "skip_training": false,
    "quantization_bits": [16],
    "output_dir": "experiment_results_Qwen",

    "eval_interval": 10000,
    "num_eval_texts": 10,

    "lm_batch_size": 1,
    "buffer_size": 256,
    "batch_size": 16,
    "dtype": "fp16",
    "buffer_mult": 2,
    "gradient_accumulation_steps": 2,

    "device": "cuda",

    "name": "Qwen/Qwen2.5-0.5B",
    "num_hidden_layers": 24,
    "num_attention_heads": 14,
    "max_seq_len": 8192,
    "hidden_size": 896,
    "vocab_size": 151936
} 