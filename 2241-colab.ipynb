{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ta6KkToOAF1M"
      },
      "source": [
        "# Notebook to run learned kv compression scripts on colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prGnb-vKAnzs"
      },
      "source": [
        "Download Repo and Install Requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "YbnT8hMBAE49",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "# Download Repo\n",
        "%cd /content\n",
        "!rm -rf learned-kv-compression\n",
        "!git clone -b colab https://henro25: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@github.com/henro25/learned-kv-compression\n",
        "%cd /content/learned-kv-compression/\n",
        "%ls\n",
        "\n",
        "# Install Requirements\n",
        "%pip install -r colab_requirements.txt\n",
        "%pip uninstall gcsfs -y\n",
        "%pip install --upgrade fsspec==2025.3.2\n",
        "%pip install gcsfs==2024.12.0\n",
        "%pip install --upgrade datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7vdgntcAana"
      },
      "source": [
        "## Training the Autoencoder\n",
        "\n",
        "This trains an autoencoder that compresses each KV vector to a 16-dimensional latent representation using 1000 texts from WikiText-103."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7idaakurATWT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "785fb2f0-9350-41e2-c0ba-84d3d811bb09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-07 03:56:18.680561: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1743998178.703044    2508 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1743998178.709487    2508 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-04-07 03:56:18.730718: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "{'batch_size': 32,\n",
            " 'buffer_mult': 2,\n",
            " 'config': 'src/configs/default_config.json',\n",
            " 'eval_interval': 100,\n",
            " 'head_dim': 64,\n",
            " 'input_dim': 64,\n",
            " 'latent_dim': 16,\n",
            " 'lm_batch_size': 1,\n",
            " 'lr': 0.0001,\n",
            " 'name': 'distilgpt2',\n",
            " 'num_epochs': 10,\n",
            " 'num_eval_texts': 100,\n",
            " 'num_hidden_layers': 6,\n",
            " 'num_key_value_heads': 12,\n",
            " 'num_train_texts': 1000,\n",
            " 'output_dir': 'models/distilgpt2_16',\n",
            " 'seed': 42}\n",
            "Using 1000 texts for training and 100 texts for evaluation\n",
            "Epoch 1/10: 100% 31/31 [00:00<00:00, 105.85it/s]\n",
            "Epoch 1/10, Average Loss: 1.4157\n",
            "Checkpoint saved at models/distilgpt2_16/autoencoder_epoch_1.pth\n",
            "Epoch 2/10: 100% 31/31 [00:00<00:00, 116.04it/s]\n",
            "Epoch 2/10, Average Loss: 1.3920\n",
            "Checkpoint saved at models/distilgpt2_16/autoencoder_epoch_2.pth\n",
            "Epoch 3/10: 100% 31/31 [00:00<00:00, 164.94it/s]\n",
            "Epoch 3/10, Average Loss: 1.3861\n",
            "Checkpoint saved at models/distilgpt2_16/autoencoder_epoch_3.pth\n",
            "Epoch 4/10: 100% 31/31 [00:00<00:00, 159.38it/s]\n",
            "Epoch 4/10, Average Loss: 1.3727\n",
            "Checkpoint saved at models/distilgpt2_16/autoencoder_epoch_4.pth\n",
            "Epoch 5/10: 100% 31/31 [00:00<00:00, 174.04it/s]\n",
            "Epoch 5/10, Average Loss: 1.3598\n",
            "Checkpoint saved at models/distilgpt2_16/autoencoder_epoch_5.pth\n",
            "Epoch 6/10: 100% 31/31 [00:00<00:00, 155.54it/s]\n",
            "Epoch 6/10, Average Loss: 1.3420\n",
            "Checkpoint saved at models/distilgpt2_16/autoencoder_epoch_6.pth\n",
            "Epoch 7/10: 100% 31/31 [00:00<00:00, 156.54it/s]\n",
            "Epoch 7/10, Average Loss: 1.3729\n",
            "Checkpoint saved at models/distilgpt2_16/autoencoder_epoch_7.pth\n",
            "Epoch 8/10: 100% 31/31 [00:00<00:00, 117.38it/s]\n",
            "Epoch 8/10, Average Loss: 1.3766\n",
            "Checkpoint saved at models/distilgpt2_16/autoencoder_epoch_8.pth\n",
            "Epoch 9/10: 100% 31/31 [00:00<00:00, 138.75it/s]\n",
            "Epoch 9/10, Average Loss: 1.3295\n",
            "Checkpoint saved at models/distilgpt2_16/autoencoder_epoch_9.pth\n",
            "Epoch 10/10: 100% 31/31 [00:00<00:00, 140.26it/s]\n",
            "Epoch 10/10, Average Loss: 1.3690\n",
            "Checkpoint saved at models/distilgpt2_16/autoencoder_epoch_10.pth\n",
            "Final model saved at models/distilgpt2_16/autoencoder_final.pth\n",
            "Training complete!\n",
            "Best evaluation loss: inf\n",
            "Models saved in models/distilgpt2_16\n"
          ]
        }
      ],
      "source": [
        "!python -m src.dictionary_learning.train \\\n",
        "    --name distilgpt2 \\\n",
        "    --latent_dim 16 \\\n",
        "    --num_epochs 10 \\\n",
        "    --batch_size 32 \\\n",
        "    --output_dir models/distilgpt2_16 \\\n",
        "    --num_train_texts 1000"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run a quick test for KV Cache compression with minimal parameters"
      ],
      "metadata": {
        "id": "D6oJq5qtZTwj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!./quick_test.sh"
      ],
      "metadata": {
        "id": "j_99ro74ZTZw",
        "outputId": "ed8e582d-24d8-414d-813a-94fdceb84f1c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==== Quick Test: KV Cache Compression ====\n",
            "Model: distilgpt2\n",
            "Latent dimension: 16\n",
            "Number of epochs: 1\n",
            "Number of training texts: 10\n",
            "Cache size: 1 MB\n",
            "Batch size: 512\n",
            "Number of runs: 3\n",
            "========================================\n",
            "Step 1: Training autoencoder...\n",
            "2025-04-07 04:03:54.360080: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1743998634.382616    4577 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1743998634.389000    4577 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-04-07 04:03:54.410974: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "{'batch_size': 2,\n",
            " 'buffer_mult': 2,\n",
            " 'config': 'src/configs/default_config.json',\n",
            " 'eval_interval': 100,\n",
            " 'head_dim': 64,\n",
            " 'input_dim': 64,\n",
            " 'latent_dim': 16,\n",
            " 'lm_batch_size': 1,\n",
            " 'lr': 0.0001,\n",
            " 'name': 'distilgpt2',\n",
            " 'num_epochs': 1,\n",
            " 'num_eval_texts': 100,\n",
            " 'num_hidden_layers': 6,\n",
            " 'num_key_value_heads': 12,\n",
            " 'num_train_texts': 10,\n",
            " 'output_dir': 'test_models/distilgpt2_latent16',\n",
            " 'seed': 42}\n",
            "Using 10 texts for training and 100 texts for evaluation\n",
            "Epoch 1/1: 100% 5/5 [00:00<00:00, 50.13it/s]\n",
            "Epoch 1/1, Average Loss: 0.5002\n",
            "Checkpoint saved at test_models/distilgpt2_latent16/autoencoder_epoch_1.pth\n",
            "Final model saved at test_models/distilgpt2_latent16/autoencoder_final.pth\n",
            "Training complete!\n",
            "Best evaluation loss: inf\n",
            "Models saved in test_models/distilgpt2_latent16\n",
            "Step 2: Running benchmark test...\n",
            "2025-04-07 04:04:23.436202: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1743998663.454736    4702 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1743998663.460351    4702 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-04-07 04:04:23.482411: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Loaded autoencoder from test_models/distilgpt2_latent16/autoencoder_final.pth\n",
            "Benchmarking different cache sizes:   0% 0/1 [00:00<?, ?it/s]\n",
            "Running benchmark for 1.0MB KV cache\n",
            "\n",
            "Generating 1.0MB KV cache:   0% 0/56 [00:00<?, ?it/s]\u001b[A\n",
            "Generating 1.0MB KV cache:  18% 10/56 [00:00<00:01, 35.66it/s]\u001b[A\n",
            "Generating 1.0MB KV cache:  71% 40/56 [00:00<00:00, 88.84it/s] \n",
            "Generated KV cache of size: 0.98MB (56 tokens)\n",
            "Measuring baseline (no compression)...\n",
            "Compressing KV cache...\n",
            "Measuring with compression...\n",
            "Compression ratio: 4.00x\n",
            "Speedup factor: 0.89x\n",
            "Time to first token (baseline): 0.0057s ± 0.0004s\n",
            "Time to first token (compressed): 0.0064s ± 0.0002s\n",
            "Benchmarking different cache sizes: 100% 1/1 [00:00<00:00,  1.96it/s]\n",
            "Results saved to test_results/benchmark_results.json\n",
            "Quick test completed!\n",
            "Check test_results for results and visualizations.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}