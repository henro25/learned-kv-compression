==== KV Cache Compression Experiment ====
Model: distilgpt2
Latent dimensions: 8 16 32
Cache sizes (MB): 1 10 100 1000 3000
Number of epochs: 5
Number of training texts: 1000
Batch size: 1024
Number of runs for timing: 5
Output directory: experiment_results_distilgpt2
========================================
Starting experiment at Wed Apr  2 22:11:37 EDT 2025
2025-04-02 22:11:37,443 [INFO] 
================================================================================
2025-04-02 22:11:37,443 [INFO] Starting KV Cache Compression Experiments
2025-04-02 22:11:37,443 [INFO] ================================================================================
2025-04-02 22:11:37,443 [INFO] Model: distilgpt2
2025-04-02 22:11:37,444 [INFO] Latent dimensions: [8, 16, 32]
2025-04-02 22:11:37,444 [INFO] KV cache sizes (MB): [1.0, 10.0, 100.0, 1000.0, 3000.0]
2025-04-02 22:11:37,444 [INFO] Number of epochs: 5
2025-04-02 22:11:37,444 [INFO] Number of training texts: 1000
2025-04-02 22:11:37,444 [INFO] Batch size: 1024
2025-04-02 22:11:37,444 [INFO] Number of runs for timing: 5
2025-04-02 22:11:37,444 [INFO] Maximum token chunk size: 128
2025-04-02 22:11:37,444 [INFO] Output directory: experiment_results_distilgpt2
2025-04-02 22:11:37,444 [INFO] 
================================================================================
2025-04-02 22:11:37,444 [INFO] Processing latent_dim=8
2025-04-02 22:11:37,444 [INFO] ================================================================================
2025-04-02 22:11:38,944 [INFO] CUDA cache cleared
2025-04-02 22:11:38,974 [INFO] Garbage collector run
2025-04-02 22:11:38,974 [INFO] 
================================================================================
2025-04-02 22:11:38,974 [INFO] Training autoencoder with latent_dim=8
2025-04-02 22:11:38,974 [INFO] ================================================================================
2025-04-02 22:11:38,974 [INFO] Running: python -m src.dictionary_learning.train --name distilgpt2 --latent_dim 8 --num_epochs 5 --num_train_texts 1000 --output_dir experiment_results_distilgpt2/distilgpt2_latent8
2025-04-02 22:11:59,844 [INFO] Command completed successfully
2025-04-02 22:11:59,845 [INFO] Autoencoder trained and saved to experiment_results_distilgpt2/distilgpt2_latent8/autoencoder_final.pth
2025-04-02 22:11:59,846 [INFO] CUDA cache cleared
2025-04-02 22:11:59,876 [INFO] Garbage collector run
2025-04-02 22:11:59,876 [INFO] 
================================================================================
2025-04-02 22:11:59,876 [INFO] Running benchmark with latent_dim=8
2025-04-02 22:11:59,876 [INFO] ================================================================================
2025-04-02 22:11:59,876 [INFO] Running: python -m src.inference.benchmark --model distilgpt2 --autoencoder experiment_results_distilgpt2/distilgpt2_latent8/autoencoder_final.pth --latent_dim 8 --batch_size 1024 --num_runs 5 --max_token_chunk 128 --sizes 1.0 10.0 100.0 1000.0 3000.0 --output experiment_results_distilgpt2/benchmark_distilgpt2_latent8
2025-04-02 22:12:04,435 [ERROR] Command failed with exit code 1
2025-04-02 22:12:04,435 [ERROR] STDOUT: 
2025-04-02 22:12:04,435 [ERROR] STDERR: Traceback (most recent call last):
  File "/n/sw/Mambaforge-23.11.0-0/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/n/sw/Mambaforge-23.11.0-0/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/n/holylabs/LABS/meng_lab/Lab/learned-kv-compression/src/inference/benchmark.py", line 21, in <module>
    from src.inference.inference import compress_kv_cache, decompress_kv_cache, generate_kv_cache
ImportError: cannot import name 'compress_kv_cache' from 'src.inference.inference' (/n/holylabs/LABS/meng_lab/Lab/learned-kv-compression/src/inference/inference.py)

2025-04-02 22:12:04,435 [ERROR] Failed to run benchmark with latent_dim=8
2025-04-02 22:12:06,438 [INFO] 
================================================================================
2025-04-02 22:12:06,438 [INFO] Processing latent_dim=16
2025-04-02 22:12:06,438 [INFO] ================================================================================
2025-04-02 22:12:06,438 [INFO] CUDA cache cleared
2025-04-02 22:12:06,470 [INFO] Garbage collector run
2025-04-02 22:12:06,470 [INFO] 
================================================================================
2025-04-02 22:12:06,470 [INFO] Training autoencoder with latent_dim=16
2025-04-02 22:12:06,470 [INFO] ================================================================================
2025-04-02 22:12:06,470 [INFO] Running: python -m src.dictionary_learning.train --name distilgpt2 --latent_dim 16 --num_epochs 5 --num_train_texts 1000 --output_dir experiment_results_distilgpt2/distilgpt2_latent16
2025-04-02 22:12:27,280 [INFO] Command completed successfully
2025-04-02 22:12:27,282 [INFO] Autoencoder trained and saved to experiment_results_distilgpt2/distilgpt2_latent16/autoencoder_final.pth
2025-04-02 22:12:27,282 [INFO] CUDA cache cleared
2025-04-02 22:12:27,307 [INFO] Garbage collector run
2025-04-02 22:12:27,307 [INFO] 
================================================================================
2025-04-02 22:12:27,308 [INFO] Running benchmark with latent_dim=16
2025-04-02 22:12:27,308 [INFO] ================================================================================
2025-04-02 22:12:27,308 [INFO] Running: python -m src.inference.benchmark --model distilgpt2 --autoencoder experiment_results_distilgpt2/distilgpt2_latent16/autoencoder_final.pth --latent_dim 16 --batch_size 1024 --num_runs 5 --max_token_chunk 128 --sizes 1.0 10.0 100.0 1000.0 3000.0 --output experiment_results_distilgpt2/benchmark_distilgpt2_latent16
2025-04-02 22:12:31,848 [ERROR] Command failed with exit code 1
2025-04-02 22:12:31,848 [ERROR] STDOUT: 
2025-04-02 22:12:31,848 [ERROR] STDERR: Traceback (most recent call last):
  File "/n/sw/Mambaforge-23.11.0-0/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/n/sw/Mambaforge-23.11.0-0/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/n/holylabs/LABS/meng_lab/Lab/learned-kv-compression/src/inference/benchmark.py", line 21, in <module>
    from src.inference.inference import compress_kv_cache, decompress_kv_cache, generate_kv_cache
ImportError: cannot import name 'compress_kv_cache' from 'src.inference.inference' (/n/holylabs/LABS/meng_lab/Lab/learned-kv-compression/src/inference/inference.py)

2025-04-02 22:12:31,848 [ERROR] Failed to run benchmark with latent_dim=16
2025-04-02 22:12:33,850 [INFO] 
================================================================================
2025-04-02 22:12:33,850 [INFO] Processing latent_dim=32
2025-04-02 22:12:33,850 [INFO] ================================================================================
2025-04-02 22:12:33,850 [INFO] CUDA cache cleared
2025-04-02 22:12:33,882 [INFO] Garbage collector run
2025-04-02 22:12:33,882 [INFO] 
================================================================================
2025-04-02 22:12:33,882 [INFO] Training autoencoder with latent_dim=32
2025-04-02 22:12:33,882 [INFO] ================================================================================
2025-04-02 22:12:33,882 [INFO] Running: python -m src.dictionary_learning.train --name distilgpt2 --latent_dim 32 --num_epochs 5 --num_train_texts 1000 --output_dir experiment_results_distilgpt2/distilgpt2_latent32
2025-04-02 22:12:57,093 [INFO] Command completed successfully
2025-04-02 22:12:57,095 [INFO] Autoencoder trained and saved to experiment_results_distilgpt2/distilgpt2_latent32/autoencoder_final.pth
2025-04-02 22:12:57,095 [INFO] CUDA cache cleared
2025-04-02 22:12:57,120 [INFO] Garbage collector run
2025-04-02 22:12:57,121 [INFO] 
================================================================================
2025-04-02 22:12:57,121 [INFO] Running benchmark with latent_dim=32
2025-04-02 22:12:57,121 [INFO] ================================================================================
2025-04-02 22:12:57,121 [INFO] Running: python -m src.inference.benchmark --model distilgpt2 --autoencoder experiment_results_distilgpt2/distilgpt2_latent32/autoencoder_final.pth --latent_dim 32 --batch_size 1024 --num_runs 5 --max_token_chunk 128 --sizes 1.0 10.0 100.0 1000.0 3000.0 --output experiment_results_distilgpt2/benchmark_distilgpt2_latent32
2025-04-02 22:13:01,688 [ERROR] Command failed with exit code 1
2025-04-02 22:13:01,688 [ERROR] STDOUT: 
2025-04-02 22:13:01,688 [ERROR] STDERR: Traceback (most recent call last):
  File "/n/sw/Mambaforge-23.11.0-0/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/n/sw/Mambaforge-23.11.0-0/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/n/holylabs/LABS/meng_lab/Lab/learned-kv-compression/src/inference/benchmark.py", line 21, in <module>
    from src.inference.inference import compress_kv_cache, decompress_kv_cache, generate_kv_cache
ImportError: cannot import name 'compress_kv_cache' from 'src.inference.inference' (/n/holylabs/LABS/meng_lab/Lab/learned-kv-compression/src/inference/inference.py)

2025-04-02 22:13:01,688 [ERROR] Failed to run benchmark with latent_dim=32
2025-04-02 22:13:03,690 [INFO] 
================================================================================
2025-04-02 22:13:03,691 [INFO] Experiment Summary
2025-04-02 22:13:03,691 [INFO] ================================================================================
2025-04-02 22:13:03,691 [INFO] Model: distilgpt2
2025-04-02 22:13:03,691 [INFO] Latent dimensions tested: [8, 16, 32]
2025-04-02 22:13:03,691 [INFO] KV cache sizes tested: [1.0, 10.0, 100.0, 1000.0, 3000.0] MB
2025-04-02 22:13:03,691 [INFO] Batch size: 1024
2025-04-02 22:13:03,691 [INFO] Number of runs for timing: 5
2025-04-02 22:13:03,691 [INFO] Total runtime: 0h 1m 26.25s
2025-04-02 22:13:03,691 [INFO] Results saved to: experiment_results_distilgpt2
2025-04-02 22:13:03,691 [WARNING] No successful results were produced
2025-04-02 22:13:03,691 [WARNING] Failed dimensions:
2025-04-02 22:13:03,691 [WARNING] - Latent dim 8: benchmark failed
2025-04-02 22:13:03,691 [WARNING] - Latent dim 16: benchmark failed
2025-04-02 22:13:03,691 [WARNING] - Latent dim 32: benchmark failed
2025-04-02 22:13:03,691 [INFO] ================================================================================
2025-04-02 22:13:03,692 [INFO] Summary saved to experiment_results_distilgpt2/experiment_summary.txt
Experiment completed at Wed Apr  2 22:13:04 EDT 2025
Generating comparison report...
Traceback (most recent call last):
  File "/n/sw/Mambaforge-23.11.0-0/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/n/sw/Mambaforge-23.11.0-0/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/n/holylabs/LABS/meng_lab/Lab/learned-kv-compression/src/analysis/compare_results.py", line 359, in <module>
    main() 
  File "/n/holylabs/LABS/meng_lab/Lab/learned-kv-compression/src/analysis/compare_results.py", line 343, in main
    df = load_results(args.results)
  File "/n/holylabs/LABS/meng_lab/Lab/learned-kv-compression/src/analysis/compare_results.py", line 53, in load_results
    "actual_size_mb": data["actual_size_mb"]
KeyError: 'actual_size_mb'
Loading results from: ['experiment_results_distilgpt2/benchmark_distilgpt2_latent8', 'experiment_results_distilgpt2/benchmark_distilgpt2_latent16', 'experiment_results_distilgpt2/benchmark_distilgpt2_latent32']
Experiment and analysis complete!
